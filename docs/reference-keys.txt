intro
motivation
how-do-we-start-using-rtorch
getting-the-pytorch-version
pytorch-configuration
what-can-you-do-with-rtorch
callable-pytorch-modules
the-torchvision-module
np-the-numpy-module
python-built-in-functions
rtorch-vs-pytorch-whats-different
calling-objects-from-pytorch
call-a-module-from-pytorch
show-the-attributes-methods-of-a-class-or-pytorch-object
enumeration
how-to-iterate
using-enumerate-and-iterate
using-a-for-loop-to-iterate
zero-gradient
version-in-python
version-in-r
transform-a-tensor
build-a-model-class
example-1
example-2-logistic-regression
convert-a-tensor-to-numpy-object
convert-a-numpy-object-to-an-r-object
tensors
tensor-data-types
arithmetic-of-tensors
add-tensors
multiply-a-tensor-by-a-scalar
numpy-and-pytorch
tuples-python-and-vectors-r
make-a-numpy-array-a-tensor-with-as_tensor
tensor-to-array-and-viceversa
create-tensors
tensor-resizing
concatenate-tensors
reshape-tensors
with-function-chunk
with-index_select
special-tensors
identity-matrix
ones
zeros
tensor-fill
initialize-a-linear-or-log-scale-tensor
inplace-out-of-place
access-to-tensor-elements
using-indices-to-access-elements
using-the-take-function
other-tensor-operations
cross-product
dot-product
logical-operations
logical-not
distributions
uniform-matrix
binomial-distribution
exponential-distribution
weibull-distribution
linearalgebra
scalars
vectors
matrices
d-tensors
transpose-of-a-matrix
vectors-special-case-of-a-matrix
tensor-arithmetic
add-a-scalar-to-a-tensor
multiplying-tensors
dot-product-1
dot-product-of-2d-array-using-python
dot-product-of-2d-array-using-r
dot-product-with-mm-and-matmul-functions
mnistdigits
hyperparameters
read-datasets
define-the-model
training
prediction
save-the-model
example-1-python-mnist-handwritten-digits
a-classic-classification-problem
simple-linear-regression
introduction
generate-the-dataset
convert-arrays-to-tensors
converting-from-numpy-to-tensor
creating-the-network-model
optimizer-and-loss
training-1
results
rainfall.-linear-regression
training-data
convert-arrays-to-tensors-1
build-the-model
generate-predictions
loss-function
step-by-step-process
compute-the-losses
compute-gradients
reset-the-gradients
adjust-weights-and-biases-using-gradient-descent
all-together-train-for-multiple-epochs
a-two-layer-neural-network
load-the-libraries
dataset
run-the-model-for-50-iterations
run-it-at-100-iterations
original-pytorch-code
a-very-simple-neural-network
introduction-1
select-device
create-the-dataset
define-the-model-1
loss-function-1
iterate-through-batches
neural-networks-2
nn2-1
nn2-2
working-with-data.frame
load-pytorch-libraries
load-dataset
summary-statistics-for-tensors
using-data.frame
working-with-data.table
load-pytorch-libraries-1
load-dataset-1
read-the-datasets-without-normalization
using-data.table
appendixA
basic-statistical-terms
five-number-summary
appendixB
the-sigmoid-function
the-relu-function
the-tanh-function
the-softmax-activation-function
coding-your-own-activation-functions-in-python
softmax-in-python
