<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Tensors | A Minimal rTorch Book</title>
  <meta name="description" content="This is a minimal tutorial about using the rTorch package to have fun while doing machine learning. This book was written with bookdown." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Tensors | A Minimal rTorch Book" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal tutorial about using the rTorch package to have fun while doing machine learning. This book was written with bookdown." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Tensors | A Minimal rTorch Book" />
  
  <meta name="twitter:description" content="This is a minimal tutorial about using the rTorch package to have fun while doing machine learning. This book was written with bookdown." />
  

<meta name="author" content="Alfonso R. Reyes" />


<meta name="date" content="2020-10-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="rtorch-vs-pytorch-whats-different.html"/>
<link rel="next" href="linearalgebra.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>

<script>
/* ========================================================================
 * Bootstrap: transition.js v3.3.7
 * http://getbootstrap.com/javascript/#transitions
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // CSS TRANSITION SUPPORT (Shoutout: http://www.modernizr.com/)
  // ============================================================

  function transitionEnd() {
    var el = document.createElement('bootstrap')

    var transEndEventNames = {
      WebkitTransition : 'webkitTransitionEnd',
      MozTransition    : 'transitionend',
      OTransition      : 'oTransitionEnd otransitionend',
      transition       : 'transitionend'
    }

    for (var name in transEndEventNames) {
      if (el.style[name] !== undefined) {
        return { end: transEndEventNames[name] }
      }
    }

    return false // explicit for ie8 (  ._.)
  }

  // http://blog.alexmaccaw.com/css-transitions
  $.fn.emulateTransitionEnd = function (duration) {
    var called = false
    var $el = this
    $(this).one('bsTransitionEnd', function () { called = true })
    var callback = function () { if (!called) $($el).trigger($.support.transition.end) }
    setTimeout(callback, duration)
    return this
  }

  $(function () {
    $.support.transition = transitionEnd()

    if (!$.support.transition) return

    $.event.special.bsTransitionEnd = {
      bindType: $.support.transition.end,
      delegateType: $.support.transition.end,
      handle: function (e) {
        if ($(e.target).is(this)) return e.handleObj.handler.apply(this, arguments)
      }
    }
  })

}(jQuery);
</script>
<script>
/* ========================================================================
 * Bootstrap: collapse.js v3.3.7
 * http://getbootstrap.com/javascript/#collapse
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */

/* jshint latedef: false */

+function ($) {
  'use strict';

  // COLLAPSE PUBLIC CLASS DEFINITION
  // ================================

  var Collapse = function (element, options) {
    this.$element      = $(element)
    this.options       = $.extend({}, Collapse.DEFAULTS, options)
    this.$trigger      = $('[data-toggle="collapse"][href="#' + element.id + '"],' +
                           '[data-toggle="collapse"][data-target="#' + element.id + '"]')
    this.transitioning = null

    if (this.options.parent) {
      this.$parent = this.getParent()
    } else {
      this.addAriaAndCollapsedClass(this.$element, this.$trigger)
    }

    if (this.options.toggle) this.toggle()
  }

  Collapse.VERSION  = '3.3.7'

  Collapse.TRANSITION_DURATION = 350

  Collapse.DEFAULTS = {
    toggle: true
  }

  Collapse.prototype.dimension = function () {
    var hasWidth = this.$element.hasClass('width')
    return hasWidth ? 'width' : 'height'
  }

  Collapse.prototype.show = function () {
    if (this.transitioning || this.$element.hasClass('in')) return

    var activesData
    var actives = this.$parent && this.$parent.children('.panel').children('.in, .collapsing')

    if (actives && actives.length) {
      activesData = actives.data('bs.collapse')
      if (activesData && activesData.transitioning) return
    }

    var startEvent = $.Event('show.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    if (actives && actives.length) {
      Plugin.call(actives, 'hide')
      activesData || actives.data('bs.collapse', null)
    }

    var dimension = this.dimension()

    this.$element
      .removeClass('collapse')
      .addClass('collapsing')[dimension](0)
      .attr('aria-expanded', true)

    this.$trigger
      .removeClass('collapsed')
      .attr('aria-expanded', true)

    this.transitioning = 1

    var complete = function () {
      this.$element
        .removeClass('collapsing')
        .addClass('collapse in')[dimension]('')
      this.transitioning = 0
      this.$element
        .trigger('shown.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    var scrollSize = $.camelCase(['scroll', dimension].join('-'))

    this.$element
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)[dimension](this.$element[0][scrollSize])
  }

  Collapse.prototype.hide = function () {
    if (this.transitioning || !this.$element.hasClass('in')) return

    var startEvent = $.Event('hide.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    var dimension = this.dimension()

    this.$element[dimension](this.$element[dimension]())[0].offsetHeight

    this.$element
      .addClass('collapsing')
      .removeClass('collapse in')
      .attr('aria-expanded', false)

    this.$trigger
      .addClass('collapsed')
      .attr('aria-expanded', false)

    this.transitioning = 1

    var complete = function () {
      this.transitioning = 0
      this.$element
        .removeClass('collapsing')
        .addClass('collapse')
        .trigger('hidden.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    this.$element
      [dimension](0)
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)
  }

  Collapse.prototype.toggle = function () {
    this[this.$element.hasClass('in') ? 'hide' : 'show']()
  }

  Collapse.prototype.getParent = function () {
    return $(this.options.parent)
      .find('[data-toggle="collapse"][data-parent="' + this.options.parent + '"]')
      .each($.proxy(function (i, element) {
        var $element = $(element)
        this.addAriaAndCollapsedClass(getTargetFromTrigger($element), $element)
      }, this))
      .end()
  }

  Collapse.prototype.addAriaAndCollapsedClass = function ($element, $trigger) {
    var isOpen = $element.hasClass('in')

    $element.attr('aria-expanded', isOpen)
    $trigger
      .toggleClass('collapsed', !isOpen)
      .attr('aria-expanded', isOpen)
  }

  function getTargetFromTrigger($trigger) {
    var href
    var target = $trigger.attr('data-target')
      || (href = $trigger.attr('href')) && href.replace(/.*(?=#[^\s]+$)/, '') // strip for ie7

    return $(target)
  }


  // COLLAPSE PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this   = $(this)
      var data    = $this.data('bs.collapse')
      var options = $.extend({}, Collapse.DEFAULTS, $this.data(), typeof option == 'object' && option)

      if (!data && options.toggle && /show|hide/.test(option)) options.toggle = false
      if (!data) $this.data('bs.collapse', (data = new Collapse(this, options)))
      if (typeof option == 'string') data[option]()
    })
  }

  var old = $.fn.collapse

  $.fn.collapse             = Plugin
  $.fn.collapse.Constructor = Collapse


  // COLLAPSE NO CONFLICT
  // ====================

  $.fn.collapse.noConflict = function () {
    $.fn.collapse = old
    return this
  }


  // COLLAPSE DATA-API
  // =================

  $(document).on('click.bs.collapse.data-api', '[data-toggle="collapse"]', function (e) {
    var $this   = $(this)

    if (!$this.attr('data-target')) e.preventDefault()

    var $target = getTargetFromTrigger($this)
    var data    = $target.data('bs.collapse')
    var option  = data ? 'toggle' : $this.data()

    Plugin.call($target, option)
  })

}(jQuery);
</script>
<script>
window.initializeCodeFolding = function(show) {

  // handlers for show-all and hide all
  $("#rmd-show-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
      // R show code
      $('div.r-code-collapse').each(function() {
        $(this).collapse('show');
      });
      // Python show code
      $('div.py-code-collapse').each(function() {
        $(this).collapse('show');
      });    
  });
  $("#rmd-hide-all-code").click(function() {
      // close the dropdown menu when an option is clicked
      $("#allCodeButton").dropdown("toggle");
      // Hide R code
      $('div.r-code-collapse').each(function() {
        $(this).collapse('hide');
      });
      // Hide Python code
      $('div.py-code-collapse').each(function() {
        $(this).collapse('hide');
      });
  });

  // index for unique code element ids
  var r_currentIndex  = 1;   // for R code
  var py_currentIndex = 1;   // for Python code

  // select Python chunks
  var pyCodeBlocks = $('pre.python');
  pyCodeBlocks.each(function() {
    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse py-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'pycode-643E0F36' + py_currentIndex++;
    div.attr('id', id);
    // "this" refers the code chunk
    $(this).before(div);
    $(this).detach().appendTo(div);
    $(this).css('background-color','#ebfaeb');  // change color of chunk background
    
    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide Python code' : 'Python code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);    
        
    // change the background color of the button
    showCodeButton.css('background-color','#009900');
        
    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');

    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);

    div.before(buttonRow);    
    
    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('Python code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide Python code');
    });  
   });
  

  // select all R code blocks
  // var rCodeBlocks = $('pre.sourceCode, pre.r, pre.bash, pre.sql, pre.cpp, pre.stan');
  // adding pre.sourceCode confuses the Python button
  var rCodeBlocks = $('pre.r, pre.bash, pre.sql, pre.cpp, pre.stan');
  rCodeBlocks.each(function() {
    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse r-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'rcode-643E0F36' + r_currentIndex++;
    div.attr('id', id);
    $(this).before(div);
    $(this).detach().appendTo(div);
    $(this).css('background-color','#e6faff'); // change color of chunk background

    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide R code' : 'R code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);
    
    // change the background color of the button        
    showCodeButton.css('background-color','#0000ff');
    
    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');

    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);

    div.before(buttonRow);

    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('R code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide R code');
    });
  });

}
</script>
<script>
/* ========================================================================
 * Bootstrap: dropdown.js v3.3.7
 * http://getbootstrap.com/javascript/#dropdowns
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // DROPDOWN CLASS DEFINITION
  // =========================

  var backdrop = '.dropdown-backdrop'
  var toggle   = '[data-toggle="dropdown"]'
  var Dropdown = function (element) {
    $(element).on('click.bs.dropdown', this.toggle)
  }

  Dropdown.VERSION = '3.3.7'

  function getParent($this) {
    var selector = $this.attr('data-target')

    if (!selector) {
      selector = $this.attr('href')
      selector = selector && /#[A-Za-z]/.test(selector) && selector.replace(/.*(?=#[^\s]*$)/, '') // strip for ie7
    }

    var $parent = selector && $(selector)

    return $parent && $parent.length ? $parent : $this.parent()
  }

  function clearMenus(e) {
    if (e && e.which === 3) return
    $(backdrop).remove()
    $(toggle).each(function () {
      var $this         = $(this)
      var $parent       = getParent($this)
      var relatedTarget = { relatedTarget: this }

      if (!$parent.hasClass('open')) return

      if (e && e.type == 'click' && /input|textarea/i.test(e.target.tagName) && $.contains($parent[0], e.target)) return

      $parent.trigger(e = $.Event('hide.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this.attr('aria-expanded', 'false')
      $parent.removeClass('open').trigger($.Event('hidden.bs.dropdown', relatedTarget))
    })
  }

  Dropdown.prototype.toggle = function (e) {
    var $this = $(this)

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    clearMenus()

    if (!isActive) {
      if ('ontouchstart' in document.documentElement && !$parent.closest('.navbar-nav').length) {
        // if mobile we use a backdrop because click events don't delegate
        $(document.createElement('div'))
          .addClass('dropdown-backdrop')
          .insertAfter($(this))
          .on('click', clearMenus)
      }

      var relatedTarget = { relatedTarget: this }
      $parent.trigger(e = $.Event('show.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this
        .trigger('focus')
        .attr('aria-expanded', 'true')

      $parent
        .toggleClass('open')
        .trigger($.Event('shown.bs.dropdown', relatedTarget))
    }

    return false
  }

  Dropdown.prototype.keydown = function (e) {
    if (!/(38|40|27|32)/.test(e.which) || /input|textarea/i.test(e.target.tagName)) return

    var $this = $(this)

    e.preventDefault()
    e.stopPropagation()

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    if (!isActive && e.which != 27 || isActive && e.which == 27) {
      if (e.which == 27) $parent.find(toggle).trigger('focus')
      return $this.trigger('click')
    }

    var desc = ' li:not(.disabled):visible a'
    var $items = $parent.find('.dropdown-menu' + desc)

    if (!$items.length) return

    var index = $items.index(e.target)

    if (e.which == 38 && index > 0)                 index--         // up
    if (e.which == 40 && index < $items.length - 1) index++         // down
    if (!~index)                                    index = 0

    $items.eq(index).trigger('focus')
  }


  // DROPDOWN PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this = $(this)
      var data  = $this.data('bs.dropdown')

      if (!data) $this.data('bs.dropdown', (data = new Dropdown(this)))
      if (typeof option == 'string') data[option].call($this)
    })
  }

  var old = $.fn.dropdown

  $.fn.dropdown             = Plugin
  $.fn.dropdown.Constructor = Dropdown


  // DROPDOWN NO CONFLICT
  // ====================

  $.fn.dropdown.noConflict = function () {
    $.fn.dropdown = old
    return this
  }


  // APPLY TO STANDARD DROPDOWN ELEMENTS
  // ===================================

  $(document)
    .on('click.bs.dropdown.data-api', clearMenus)
    .on('click.bs.dropdown.data-api', '.dropdown form', function (e) { e.stopPropagation() })
    .on('click.bs.dropdown.data-api', toggle, Dropdown.prototype.toggle)
    .on('keydown.bs.dropdown.data-api', toggle, Dropdown.prototype.keydown)
    .on('keydown.bs.dropdown.data-api', '.dropdown-menu', Dropdown.prototype.keydown)

}(jQuery);
</script>
<style type="text/css">
.code-folding-btn {
  margin-bottom: 4px;
}

.row { display: flex; }
.collapse { display: none; }
.in { display:block }
.pull-right > .dropdown-menu {
    right: 0;
    left: auto;
}

.dropdown-menu {
    position: absolute;
    top: 100%;
    left: 0;
    z-index: 1000;
    display: none;
    float: left;
    min-width: 160px;
    padding: 5px 0;
    margin: 2px 0 0;
    font-size: 14px;
    text-align: left;
    list-style: none;
    background-color: #fff;
    -webkit-background-clip: padding-box;
    background-clip: padding-box;
    border: 1px solid #ccc;
    border: 1px solid rgba(0,0,0,.15);
    border-radius: 4px;
    -webkit-box-shadow: 0 6px 12px rgba(0,0,0,.175);
    box-shadow: 0 6px 12px rgba(0,0,0,.175);
}

.open > .dropdown-menu {
    display: block;
    color: #ffffff;
    background-color: #ffffff;
    background-image: none;
    border-color: #92897e;
}

.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: 400;
  line-height: 1.42857143;
  color: #000000;
  white-space: nowrap;
}

.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
}

.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
  outline: 0;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #aea79f;
}

.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  cursor: not-allowed;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
}

.btn {
  display: inline-block;
  margin-bottom: 1;
  font-weight: normal;
  text-align: center;
  white-space: nowrap;
  vertical-align: middle;
  -ms-touch-action: manipulation;
      touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  padding: 4px 8px;
  font-size: 14px;
  line-height: 1.42857143;
  border-radius: 4px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #ffffff;
  text-decoration: none;
}
.btn:active,
.btn.active {
  background-image: none;
  outline: 0;
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  filter: alpha(opacity=65);
  opacity: 0.65;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #ffffff;
  background-color: #aea79f; #important
  border-color: #aea79f;
}

.btn-default:focus,
.btn-default.focus {
  color: #ffffff;
  background-color: #978e83;
  border-color: #6f675e;
}

.btn-default:hover {
  color: #ffffff;
  background-color: #978e83;
  border-color: #92897e;
}
.btn-default:active,
.btn-default.active,
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-right: 8px;
  padding-left: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-right: 12px;
  padding-left: 12px;
}
.btn-group.open .dropdown-toggle {
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  box-shadow: none;
}

</style>
<script>
var str = '<div class="btn-group pull-right" style="position: fixed; right: 50px; top: 10px; z-index: 200"><button type="button" class="btn btn-default btn-xs dropdown-toggle" id="allCodeButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="true" data-_extension-text-contrast=""><span>Code</span> <span class="caret"></span></button><ul class="dropdown-menu" style="min-width: 50px;"><li><a id="rmd-show-all-code" href="#">Show All Code</a></li><li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li></ul></div>';
document.write(str);
</script>
<script>
$(document).ready(function () {
  // show code by default. Use "show" === "hide" to hide
  window.initializeCodeFolding("show" === "show");
});
</script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span. { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">The rTorch Minimal Book</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prerequisites</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#installation"><i class="fa fa-check"></i>Installation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#python-anaconda"><i class="fa fa-check"></i>Python Anaconda</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#example"><i class="fa fa-check"></i>Example</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#automatic-installation"><i class="fa fa-check"></i>Automatic installation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Getting Started</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#motivation"><i class="fa fa-check"></i><b>1.1</b> Motivation</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#how-do-we-start-using-rtorch"><i class="fa fa-check"></i><b>1.2</b> How do we start using <code>rTorch</code></a><ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#getting-the-pytorch-version"><i class="fa fa-check"></i><b>1.2.1</b> Getting the PyTorch version</a></li>
<li class="chapter" data-level="1.2.2" data-path="intro.html"><a href="intro.html#pytorch-configuration"><i class="fa fa-check"></i><b>1.2.2</b> PyTorch configuration</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#what-can-you-do-with-rtorch"><i class="fa fa-check"></i><b>1.3</b> What can you do with <code>rTorch</code></a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#callable-pytorch-modules"><i class="fa fa-check"></i><b>1.4</b> Callable PyTorch modules</a><ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#the-torchvision-module"><i class="fa fa-check"></i><b>1.4.1</b> The <code>torchvision</code> module</a></li>
<li class="chapter" data-level="1.4.2" data-path="intro.html"><a href="intro.html#np-the-numpy-module"><i class="fa fa-check"></i><b>1.4.2</b> <code>np</code>: the <code>numpy</code> module</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#create-an-array"><i class="fa fa-check"></i>Create an array</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#reshape-an-array"><i class="fa fa-check"></i>Reshape an array</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#generate-a-random-array"><i class="fa fa-check"></i>Generate a random array</a></li>
<li><a href="intro.html#convert-a-numpy-array-to-a-pytorch-tensor">Convert a <code>numpy</code> array to a PyTorch tensor</a></li>
</ul></li>
<li class="chapter" data-level="1.4.3" data-path="intro.html"><a href="intro.html#python-built-in-functions"><i class="fa fa-check"></i><b>1.4.3</b> Python built-in functions</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#length-of-a-dataset"><i class="fa fa-check"></i>Length of a dataset</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#iterators"><i class="fa fa-check"></i>Iterators</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#types-and-instances"><i class="fa fa-check"></i>Types and instances</a></li>
</ul></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html"><i class="fa fa-check"></i><b>2</b> rTorch vs PyTorch: What’s different</a><ul>
<li class="chapter" data-level="2.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#calling-objects-from-pytorch"><i class="fa fa-check"></i><b>2.1</b> Calling objects from PyTorch</a></li>
<li class="chapter" data-level="2.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#call-a-module-from-pytorch"><i class="fa fa-check"></i><b>2.2</b> Call a module from PyTorch</a></li>
<li class="chapter" data-level="2.3" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#show-the-attributes-methods-of-a-class-or-pytorch-object"><i class="fa fa-check"></i><b>2.3</b> Show the attributes (methods) of a class or PyTorch object</a></li>
<li class="chapter" data-level="2.4" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#enumeration"><i class="fa fa-check"></i><b>2.4</b> Enumeration</a></li>
<li class="chapter" data-level="2.5" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#how-to-iterate"><i class="fa fa-check"></i><b>2.5</b> How to iterate</a><ul>
<li class="chapter" data-level="2.5.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#using-enumerate-and-iterate"><i class="fa fa-check"></i><b>2.5.1</b> Using <code>enumerate</code> and <code>iterate</code></a></li>
<li class="chapter" data-level="2.5.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#using-a-for-loop-to-iterate"><i class="fa fa-check"></i><b>2.5.2</b> Using a <code>for-loop</code> to iterate</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#zero-gradient"><i class="fa fa-check"></i><b>2.6</b> Zero gradient</a><ul>
<li class="chapter" data-level="2.6.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#version-in-python"><i class="fa fa-check"></i><b>2.6.1</b> Version in Python</a></li>
<li class="chapter" data-level="2.6.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#version-in-r"><i class="fa fa-check"></i><b>2.6.2</b> Version in R</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#transform-a-tensor"><i class="fa fa-check"></i><b>2.7</b> Transform a tensor</a></li>
<li class="chapter" data-level="2.8" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#build-a-model-class"><i class="fa fa-check"></i><b>2.8</b> Build a model class</a><ul>
<li class="chapter" data-level="2.8.1" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#example-1"><i class="fa fa-check"></i><b>2.8.1</b> Example 1</a></li>
<li class="chapter" data-level="2.8.2" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#example-2-logistic-regression"><i class="fa fa-check"></i><b>2.8.2</b> Example 2: Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#convert-a-tensor-to-numpy-object"><i class="fa fa-check"></i><b>2.9</b> Convert a tensor to <code>numpy</code> object</a></li>
<li class="chapter" data-level="2.10" data-path="rtorch-vs-pytorch-whats-different.html"><a href="rtorch-vs-pytorch-whats-different.html#convert-a-numpy-object-to-an-r-object"><i class="fa fa-check"></i><b>2.10</b> Convert a <code>numpy</code> object to an <code>R</code> object</a></li>
</ul></li>
<li class="part"><span><b>II Basic Tensor Operations</b></span></li>
<li class="chapter" data-level="3" data-path="tensors.html"><a href="tensors.html"><i class="fa fa-check"></i><b>3</b> Tensors</a><ul>
<li class="chapter" data-level="3.1" data-path="tensors.html"><a href="tensors.html#tensor-data-types"><i class="fa fa-check"></i><b>3.1</b> Tensor data types</a></li>
<li class="chapter" data-level="3.2" data-path="tensors.html"><a href="tensors.html#arithmetic-of-tensors"><i class="fa fa-check"></i><b>3.2</b> Arithmetic of tensors</a><ul>
<li class="chapter" data-level="3.2.1" data-path="tensors.html"><a href="tensors.html#add-tensors"><i class="fa fa-check"></i><b>3.2.1</b> Add tensors</a></li>
<li class="chapter" data-level="3.2.2" data-path="tensors.html"><a href="tensors.html#multiply-a-tensor-by-a-scalar"><i class="fa fa-check"></i><b>3.2.2</b> Multiply a tensor by a scalar</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="tensors.html"><a href="tensors.html#numpy-and-pytorch"><i class="fa fa-check"></i><b>3.3</b> NumPy and PyTorch</a><ul>
<li class="chapter" data-level="3.3.1" data-path="tensors.html"><a href="tensors.html#tuples-python-and-vectors-r"><i class="fa fa-check"></i><b>3.3.1</b> Tuples (Python) and vectors (R)</a></li>
<li class="chapter" data-level="3.3.2" data-path="tensors.html"><a href="tensors.html#make-a-numpy-array-a-tensor-with-as_tensor"><i class="fa fa-check"></i><b>3.3.2</b> Make a numpy array a tensor with <code>as_tensor()</code></a></li>
<li class="chapter" data-level="3.3.3" data-path="tensors.html"><a href="tensors.html#tensor-to-array-and-viceversa"><i class="fa fa-check"></i><b>3.3.3</b> Tensor to array, and viceversa</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="tensors.html"><a href="tensors.html#create-tensors"><i class="fa fa-check"></i><b>3.4</b> Create tensors</a></li>
<li class="chapter" data-level="3.5" data-path="tensors.html"><a href="tensors.html#tensor-resizing"><i class="fa fa-check"></i><b>3.5</b> Tensor resizing</a><ul>
<li class="chapter" data-level="3.5.1" data-path="tensors.html"><a href="tensors.html#concatenate-tensors"><i class="fa fa-check"></i><b>3.5.1</b> Concatenate tensors</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="tensors.html"><a href="tensors.html#reshape-tensors"><i class="fa fa-check"></i><b>3.6</b> Reshape tensors</a><ul>
<li class="chapter" data-level="3.6.1" data-path="tensors.html"><a href="tensors.html#with-function-chunk"><i class="fa fa-check"></i><b>3.6.1</b> With function <code>chunk()</code>:</a></li>
<li class="chapter" data-level="3.6.2" data-path="tensors.html"><a href="tensors.html#with-index_select"><i class="fa fa-check"></i><b>3.6.2</b> With <code>index_select()</code>:</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="tensors.html"><a href="tensors.html#special-tensors"><i class="fa fa-check"></i><b>3.7</b> Special tensors</a><ul>
<li class="chapter" data-level="3.7.1" data-path="tensors.html"><a href="tensors.html#identity-matrix"><i class="fa fa-check"></i><b>3.7.1</b> Identity matrix</a></li>
<li class="chapter" data-level="3.7.2" data-path="tensors.html"><a href="tensors.html#ones"><i class="fa fa-check"></i><b>3.7.2</b> Ones</a></li>
<li class="chapter" data-level="3.7.3" data-path="tensors.html"><a href="tensors.html#zeros"><i class="fa fa-check"></i><b>3.7.3</b> Zeros</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="tensors.html"><a href="tensors.html#tensor-fill"><i class="fa fa-check"></i><b>3.8</b> Tensor fill</a><ul>
<li class="chapter" data-level="3.8.1" data-path="tensors.html"><a href="tensors.html#initialize-a-linear-or-log-scale-tensor"><i class="fa fa-check"></i><b>3.8.1</b> Initialize a linear or log scale Tensor</a></li>
<li class="chapter" data-level="3.8.2" data-path="tensors.html"><a href="tensors.html#inplace-out-of-place"><i class="fa fa-check"></i><b>3.8.2</b> Inplace / Out-of-place</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="tensors.html"><a href="tensors.html#access-to-tensor-elements"><i class="fa fa-check"></i><b>3.9</b> Access to tensor elements</a><ul>
<li class="chapter" data-level="3.9.1" data-path="tensors.html"><a href="tensors.html#using-indices-to-access-elements"><i class="fa fa-check"></i><b>3.9.1</b> Using indices to access elements</a></li>
<li class="chapter" data-level="3.9.2" data-path="tensors.html"><a href="tensors.html#using-the-take-function"><i class="fa fa-check"></i><b>3.9.2</b> Using the <code>take</code> function</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="tensors.html"><a href="tensors.html#other-tensor-operations"><i class="fa fa-check"></i><b>3.10</b> Other tensor operations</a><ul>
<li class="chapter" data-level="3.10.1" data-path="tensors.html"><a href="tensors.html#cross-product"><i class="fa fa-check"></i><b>3.10.1</b> Cross product</a></li>
<li class="chapter" data-level="3.10.2" data-path="tensors.html"><a href="tensors.html#dot-product"><i class="fa fa-check"></i><b>3.10.2</b> Dot product</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="tensors.html"><a href="tensors.html#logical-operations"><i class="fa fa-check"></i><b>3.11</b> Logical operations</a><ul>
<li class="chapter" data-level="3.11.1" data-path="tensors.html"><a href="tensors.html#logical-not"><i class="fa fa-check"></i><b>3.11.1</b> Logical NOT</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="tensors.html"><a href="tensors.html#distributions"><i class="fa fa-check"></i><b>3.12</b> Distributions</a><ul>
<li class="chapter" data-level="3.12.1" data-path="tensors.html"><a href="tensors.html#uniform-matrix"><i class="fa fa-check"></i><b>3.12.1</b> Uniform matrix</a></li>
<li class="chapter" data-level="3.12.2" data-path="tensors.html"><a href="tensors.html#binomial-distribution"><i class="fa fa-check"></i><b>3.12.2</b> Binomial distribution</a></li>
<li class="chapter" data-level="3.12.3" data-path="tensors.html"><a href="tensors.html#exponential-distribution"><i class="fa fa-check"></i><b>3.12.3</b> Exponential distribution</a></li>
<li class="chapter" data-level="3.12.4" data-path="tensors.html"><a href="tensors.html#weibull-distribution"><i class="fa fa-check"></i><b>3.12.4</b> Weibull distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linearalgebra.html"><a href="linearalgebra.html"><i class="fa fa-check"></i><b>4</b> Linear Algebra with Torch</a><ul>
<li class="chapter" data-level="4.1" data-path="linearalgebra.html"><a href="linearalgebra.html#scalars"><i class="fa fa-check"></i><b>4.1</b> Scalars</a></li>
<li class="chapter" data-level="4.2" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors"><i class="fa fa-check"></i><b>4.2</b> Vectors</a></li>
<li class="chapter" data-level="4.3" data-path="linearalgebra.html"><a href="linearalgebra.html#matrices"><i class="fa fa-check"></i><b>4.3</b> Matrices</a></li>
<li class="chapter" data-level="4.4" data-path="linearalgebra.html"><a href="linearalgebra.html#d-tensors"><i class="fa fa-check"></i><b>4.4</b> 3D+ tensors</a></li>
<li class="chapter" data-level="4.5" data-path="linearalgebra.html"><a href="linearalgebra.html#transpose-of-a-matrix"><i class="fa fa-check"></i><b>4.5</b> Transpose of a matrix</a></li>
<li class="chapter" data-level="4.6" data-path="linearalgebra.html"><a href="linearalgebra.html#vectors-special-case-of-a-matrix"><i class="fa fa-check"></i><b>4.6</b> Vectors, special case of a matrix</a></li>
<li class="chapter" data-level="4.7" data-path="linearalgebra.html"><a href="linearalgebra.html#tensor-arithmetic"><i class="fa fa-check"></i><b>4.7</b> Tensor arithmetic</a></li>
<li class="chapter" data-level="4.8" data-path="linearalgebra.html"><a href="linearalgebra.html#add-a-scalar-to-a-tensor"><i class="fa fa-check"></i><b>4.8</b> Add a scalar to a tensor</a></li>
<li class="chapter" data-level="4.9" data-path="linearalgebra.html"><a href="linearalgebra.html#multiplying-tensors"><i class="fa fa-check"></i><b>4.9</b> Multiplying tensors</a></li>
<li class="chapter" data-level="4.10" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-1"><i class="fa fa-check"></i><b>4.10</b> Dot product</a><ul>
<li class="chapter" data-level="4.10.1" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-of-2d-array-using-python"><i class="fa fa-check"></i><b>4.10.1</b> Dot product of 2D array using Python</a></li>
<li class="chapter" data-level="4.10.2" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-of-2d-array-using-r"><i class="fa fa-check"></i><b>4.10.2</b> Dot product of 2D array using R</a></li>
<li class="chapter" data-level="4.10.3" data-path="linearalgebra.html"><a href="linearalgebra.html#dot-product-with-mm-and-matmul-functions"><i class="fa fa-check"></i><b>4.10.3</b> Dot product with <code>mm</code> and <code>matmul</code> functions</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Logistic Regression</b></span></li>
<li class="chapter" data-level="5" data-path="mnistdigits.html"><a href="mnistdigits.html"><i class="fa fa-check"></i><b>5</b> Example 1 (R): MNIST handwritten digits</a><ul>
<li class="chapter" data-level="5.1" data-path="mnistdigits.html"><a href="mnistdigits.html#hyperparameters"><i class="fa fa-check"></i><b>5.1</b> Hyperparameters</a></li>
<li class="chapter" data-level="5.2" data-path="mnistdigits.html"><a href="mnistdigits.html#read-datasets"><i class="fa fa-check"></i><b>5.2</b> Read datasets</a></li>
<li class="chapter" data-level="5.3" data-path="mnistdigits.html"><a href="mnistdigits.html#define-the-model"><i class="fa fa-check"></i><b>5.3</b> Define the model</a></li>
<li class="chapter" data-level="5.4" data-path="mnistdigits.html"><a href="mnistdigits.html#training"><i class="fa fa-check"></i><b>5.4</b> Training</a></li>
<li class="chapter" data-level="5.5" data-path="mnistdigits.html"><a href="mnistdigits.html#prediction"><i class="fa fa-check"></i><b>5.5</b> Prediction</a></li>
<li class="chapter" data-level="5.6" data-path="mnistdigits.html"><a href="mnistdigits.html#save-the-model"><i class="fa fa-check"></i><b>5.6</b> Save the model</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="example-1-python-mnist-handwritten-digits.html"><a href="example-1-python-mnist-handwritten-digits.html"><i class="fa fa-check"></i><b>6</b> Example 1 (Python): MNIST handwritten digits</a></li>
<li class="chapter" data-level="7" data-path="a-classic-classification-problem.html"><a href="a-classic-classification-problem.html"><i class="fa fa-check"></i><b>7</b> A classic classification problem</a></li>
<li class="part"><span><b>IV Linear Regression</b></span></li>
<li class="chapter" data-level="8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>8</b> Simple linear regression</a><ul>
<li class="chapter" data-level="8.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#introduction"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#generate-the-dataset"><i class="fa fa-check"></i><b>8.2</b> Generate the dataset</a></li>
<li class="chapter" data-level="8.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#convert-arrays-to-tensors"><i class="fa fa-check"></i><b>8.3</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="8.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#converting-from-numpy-to-tensor"><i class="fa fa-check"></i><b>8.4</b> Converting from numpy to tensor</a></li>
<li class="chapter" data-level="8.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#creating-the-network-model"><i class="fa fa-check"></i><b>8.5</b> Creating the network model</a></li>
<li class="chapter" data-level="8.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#optimizer-and-loss"><i class="fa fa-check"></i><b>8.6</b> Optimizer and Loss</a></li>
<li class="chapter" data-level="8.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#training-1"><i class="fa fa-check"></i><b>8.7</b> Training</a></li>
<li class="chapter" data-level="8.8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#results"><i class="fa fa-check"></i><b>8.8</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html"><i class="fa fa-check"></i><b>9</b> Rainfall. Linear Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#training-data"><i class="fa fa-check"></i><b>9.1</b> Training data</a></li>
<li class="chapter" data-level="9.2" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#convert-arrays-to-tensors-1"><i class="fa fa-check"></i><b>9.2</b> Convert arrays to tensors</a></li>
<li class="chapter" data-level="9.3" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#build-the-model"><i class="fa fa-check"></i><b>9.3</b> Build the model</a></li>
<li class="chapter" data-level="9.4" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#generate-predictions"><i class="fa fa-check"></i><b>9.4</b> Generate predictions</a></li>
<li class="chapter" data-level="9.5" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#loss-function"><i class="fa fa-check"></i><b>9.5</b> Loss Function</a></li>
<li class="chapter" data-level="9.6" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#step-by-step-process"><i class="fa fa-check"></i><b>9.6</b> Step by step process</a><ul>
<li class="chapter" data-level="9.6.1" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#compute-the-losses"><i class="fa fa-check"></i><b>9.6.1</b> Compute the losses</a></li>
<li class="chapter" data-level="9.6.2" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#compute-gradients"><i class="fa fa-check"></i><b>9.6.2</b> Compute Gradients</a></li>
<li class="chapter" data-level="9.6.3" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#reset-the-gradients"><i class="fa fa-check"></i><b>9.6.3</b> Reset the gradients</a><ul>
<li class="chapter" data-level="9.6.3.1" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#adjust-weights-and-biases-using-gradient-descent"><i class="fa fa-check"></i><b>9.6.3.1</b> Adjust weights and biases using gradient descent</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="rainfall-linear-regression.html"><a href="rainfall-linear-regression.html#all-together-train-for-multiple-epochs"><i class="fa fa-check"></i><b>9.7</b> All together: train for multiple epochs</a></li>
</ul></li>
<li class="part"><span><b>V Neural Networks</b></span></li>
<li class="chapter" data-level="10" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html"><i class="fa fa-check"></i><b>10</b> A two-layer neural network</a><ul>
<li class="chapter" data-level="10.1" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#load-the-libraries"><i class="fa fa-check"></i><b>10.1</b> Load the libraries</a></li>
<li class="chapter" data-level="10.2" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#dataset"><i class="fa fa-check"></i><b>10.2</b> Dataset</a></li>
<li class="chapter" data-level="10.3" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#run-the-model-for-50-iterations"><i class="fa fa-check"></i><b>10.3</b> Run the model for 50 iterations</a></li>
<li class="chapter" data-level="10.4" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#run-it-at-100-iterations"><i class="fa fa-check"></i><b>10.4</b> Run it at 100 iterations</a></li>
<li class="chapter" data-level="10.5" data-path="a-two-layer-neural-network.html"><a href="a-two-layer-neural-network.html#original-pytorch-code"><i class="fa fa-check"></i><b>10.5</b> Original PyTorch code</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html"><i class="fa fa-check"></i><b>11</b> A very simple neural network</a><ul>
<li class="chapter" data-level="11.1" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#introduction-1"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#select-device"><i class="fa fa-check"></i><b>11.2</b> Select device</a></li>
<li class="chapter" data-level="11.3" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#create-the-dataset"><i class="fa fa-check"></i><b>11.3</b> Create the dataset</a></li>
<li class="chapter" data-level="11.4" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#define-the-model-1"><i class="fa fa-check"></i><b>11.4</b> Define the model</a></li>
<li class="chapter" data-level="11.5" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#loss-function-1"><i class="fa fa-check"></i><b>11.5</b> Loss function</a></li>
<li class="chapter" data-level="11.6" data-path="a-very-simple-neural-network.html"><a href="a-very-simple-neural-network.html#iterate-through-batches"><i class="fa fa-check"></i><b>11.6</b> Iterate through batches</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="neural-networks-2.html"><a href="neural-networks-2.html"><i class="fa fa-check"></i><b>12</b> Neural Networks 2</a><ul>
<li class="chapter" data-level="12.1" data-path="neural-networks-2.html"><a href="neural-networks-2.html#nn2-1"><i class="fa fa-check"></i><b>12.1</b> nn2 1</a></li>
<li class="chapter" data-level="12.2" data-path="neural-networks-2.html"><a href="neural-networks-2.html#nn2-2"><i class="fa fa-check"></i><b>12.2</b> nn2 2</a></li>
</ul></li>
<li class="part"><span><b>VI PyTorch and R data structures</b></span></li>
<li class="chapter" data-level="13" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html"><i class="fa fa-check"></i><b>13</b> Working with data.frame</a><ul>
<li class="chapter" data-level="13.1" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#load-pytorch-libraries"><i class="fa fa-check"></i><b>13.1</b> Load PyTorch libraries</a></li>
<li class="chapter" data-level="13.2" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#load-dataset"><i class="fa fa-check"></i><b>13.2</b> Load dataset</a></li>
<li class="chapter" data-level="13.3" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#summary-statistics-for-tensors"><i class="fa fa-check"></i><b>13.3</b> Summary statistics for tensors</a><ul>
<li class="chapter" data-level="13.3.1" data-path="working-with-data-frame.html"><a href="working-with-data-frame.html#using-data.frame"><i class="fa fa-check"></i><b>13.3.1</b> using <code>data.frame</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="working-with-data-table.html"><a href="working-with-data-table.html"><i class="fa fa-check"></i><b>14</b> Working with data.table</a><ul>
<li class="chapter" data-level="14.1" data-path="working-with-data-table.html"><a href="working-with-data-table.html#load-pytorch-libraries-1"><i class="fa fa-check"></i><b>14.1</b> Load PyTorch libraries</a></li>
<li class="chapter" data-level="14.2" data-path="working-with-data-table.html"><a href="working-with-data-table.html#load-dataset-1"><i class="fa fa-check"></i><b>14.2</b> Load dataset</a></li>
<li class="chapter" data-level="14.3" data-path="working-with-data-table.html"><a href="working-with-data-table.html#read-the-datasets-without-normalization"><i class="fa fa-check"></i><b>14.3</b> Read the datasets without normalization</a></li>
<li class="chapter" data-level="14.4" data-path="working-with-data-table.html"><a href="working-with-data-table.html#using-data.table"><i class="fa fa-check"></i><b>14.4</b> Using <code>data.table</code></a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendixA.html"><a href="appendixA.html"><i class="fa fa-check"></i><b>A</b> Statistical Background</a><ul>
<li class="chapter" data-level="A.1" data-path="appendixA.html"><a href="appendixA.html#basic-statistical-terms"><i class="fa fa-check"></i><b>A.1</b> Basic statistical terms</a><ul>
<li class="chapter" data-level="A.1.1" data-path="appendixA.html"><a href="appendixA.html#five-number-summary"><i class="fa fa-check"></i><b>A.1.1</b> Five-number summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendixB.html"><a href="appendixB.html"><i class="fa fa-check"></i><b>B</b> Activation Functions</a><ul>
<li class="chapter" data-level="B.1" data-path="appendixB.html"><a href="appendixB.html#the-sigmoid-function"><i class="fa fa-check"></i><b>B.1</b> The Sigmoid function</a></li>
<li class="chapter" data-level="B.2" data-path="appendixB.html"><a href="appendixB.html#the-relu-function"><i class="fa fa-check"></i><b>B.2</b> The ReLU function</a></li>
<li class="chapter" data-level="B.3" data-path="appendixB.html"><a href="appendixB.html#the-tanh-function"><i class="fa fa-check"></i><b>B.3</b> The tanh function</a></li>
<li class="chapter" data-level="B.4" data-path="appendixB.html"><a href="appendixB.html#the-softmax-activation-function"><i class="fa fa-check"></i><b>B.4</b> The Softmax Activation function</a></li>
<li class="chapter" data-level="B.5" data-path="appendixB.html"><a href="appendixB.html#coding-your-own-activation-functions-in-python"><i class="fa fa-check"></i><b>B.5</b> Coding your own activation functions in Python</a><ul>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#linear-activation"><i class="fa fa-check"></i>Linear activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#sigmoid-activation"><i class="fa fa-check"></i>Sigmoid activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#hyperbolic-tangent-activation"><i class="fa fa-check"></i>Hyperbolic Tangent activation</a></li>
<li class="chapter" data-level="" data-path="appendixB.html"><a href="appendixB.html#rectifier-linear-unit-relu"><i class="fa fa-check"></i>Rectifier linear unit (ReLU)</a></li>
<li><a href="appendixB.html#visualization-with-matplotlib">Visualization with <code>matplotlib</code></a></li>
</ul></li>
<li class="chapter" data-level="B.6" data-path="appendixB.html"><a href="appendixB.html#softmax-in-python"><i class="fa fa-check"></i><b>B.6</b> Softmax in Python</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Minimal rTorch Book</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tensors" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Tensors</h1>
<p>We describe the most important PyTorch methods in this chapter.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="tensors.html#cb53-1"></a><span class="kw">library</span>(rTorch)</span></code></pre></div>
<div id="tensor-data-types" class="section level2">
<h2><span class="header-section-number">3.1</span> Tensor data types</h2>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="tensors.html#cb54-1"></a><span class="co"># Default data type</span></span>
<span id="cb54-2"><a href="tensors.html#cb54-2"></a>torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(<span class="fl">1.2</span>, <span class="dv">3</span>))<span class="op">$</span>dtype  <span class="co"># default for floating point is torch.float32</span></span>
<span id="cb54-3"><a href="tensors.html#cb54-3"></a><span class="co">#&gt; torch.float32</span></span></code></pre></div>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="tensors.html#cb55-1"></a><span class="co"># change default data type to float64</span></span>
<span id="cb55-2"><a href="tensors.html#cb55-2"></a>torch<span class="op">$</span><span class="kw">set_default_dtype</span>(torch<span class="op">$</span>float64)</span>
<span id="cb55-3"><a href="tensors.html#cb55-3"></a>torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(<span class="fl">1.2</span>, <span class="dv">3</span>))<span class="op">$</span>dtype         <span class="co"># a new floating point tensor</span></span>
<span id="cb55-4"><a href="tensors.html#cb55-4"></a><span class="co">#&gt; torch.float64</span></span></code></pre></div>
<p>There are five major type of Tensors in PyTorch</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="tensors.html#cb56-1"></a><span class="kw">library</span>(rTorch)</span>
<span id="cb56-2"><a href="tensors.html#cb56-2"></a></span>
<span id="cb56-3"><a href="tensors.html#cb56-3"></a>byte    &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">ByteTensor</span>(3L, 3L)</span>
<span id="cb56-4"><a href="tensors.html#cb56-4"></a>float   &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(3L, 3L)</span>
<span id="cb56-5"><a href="tensors.html#cb56-5"></a>double  &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">DoubleTensor</span>(3L, 3L)</span>
<span id="cb56-6"><a href="tensors.html#cb56-6"></a>long    &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">LongTensor</span>(3L, 3L)</span>
<span id="cb56-7"><a href="tensors.html#cb56-7"></a>boolean &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">BoolTensor</span>(5L, 5L)</span>
<span id="cb56-8"><a href="tensors.html#cb56-8"></a></span>
<span id="cb56-9"><a href="tensors.html#cb56-9"></a><span class="kw">message</span>(<span class="st">&quot;byte tensor&quot;</span>)</span>
<span id="cb56-10"><a href="tensors.html#cb56-10"></a><span class="co">#&gt; byte tensor</span></span>
<span id="cb56-11"><a href="tensors.html#cb56-11"></a>byte</span>
<span id="cb56-12"><a href="tensors.html#cb56-12"></a><span class="co">#&gt; tensor([[ 32,  77,  99],</span></span>
<span id="cb56-13"><a href="tensors.html#cb56-13"></a><span class="co">#&gt;         [ 18,  72, 127],</span></span>
<span id="cb56-14"><a href="tensors.html#cb56-14"></a><span class="co">#&gt;         [  0,   0,  96]], dtype=torch.uint8)</span></span>
<span id="cb56-15"><a href="tensors.html#cb56-15"></a></span>
<span id="cb56-16"><a href="tensors.html#cb56-16"></a><span class="kw">message</span>(<span class="st">&quot;float tensor&quot;</span>)</span>
<span id="cb56-17"><a href="tensors.html#cb56-17"></a><span class="co">#&gt; float tensor</span></span>
<span id="cb56-18"><a href="tensors.html#cb56-18"></a>float</span>
<span id="cb56-19"><a href="tensors.html#cb56-19"></a><span class="co">#&gt; tensor([[0., 0., 0.],</span></span>
<span id="cb56-20"><a href="tensors.html#cb56-20"></a><span class="co">#&gt;         [0., 0., 0.],</span></span>
<span id="cb56-21"><a href="tensors.html#cb56-21"></a><span class="co">#&gt;         [0., 0., 0.]], dtype=torch.float32)</span></span>
<span id="cb56-22"><a href="tensors.html#cb56-22"></a></span>
<span id="cb56-23"><a href="tensors.html#cb56-23"></a><span class="kw">message</span>(<span class="st">&quot;double&quot;</span>)</span>
<span id="cb56-24"><a href="tensors.html#cb56-24"></a><span class="co">#&gt; double</span></span>
<span id="cb56-25"><a href="tensors.html#cb56-25"></a>double</span>
<span id="cb56-26"><a href="tensors.html#cb56-26"></a><span class="co">#&gt; tensor([[6.9143e-310, 6.9143e-310, 4.9407e-324],</span></span>
<span id="cb56-27"><a href="tensors.html#cb56-27"></a><span class="co">#&gt;         [4.6429e-310,  0.0000e+00,  0.0000e+00],</span></span>
<span id="cb56-28"><a href="tensors.html#cb56-28"></a><span class="co">#&gt;         [ 0.0000e+00,  0.0000e+00, 9.5490e-313]])</span></span>
<span id="cb56-29"><a href="tensors.html#cb56-29"></a></span>
<span id="cb56-30"><a href="tensors.html#cb56-30"></a><span class="kw">message</span>(<span class="st">&quot;long&quot;</span>)</span>
<span id="cb56-31"><a href="tensors.html#cb56-31"></a><span class="co">#&gt; long</span></span>
<span id="cb56-32"><a href="tensors.html#cb56-32"></a>long</span>
<span id="cb56-33"><a href="tensors.html#cb56-33"></a><span class="co">#&gt; tensor([[             0,              0,              0],</span></span>
<span id="cb56-34"><a href="tensors.html#cb56-34"></a><span class="co">#&gt;         [             0,   193273528365, 93974339021216],</span></span>
<span id="cb56-35"><a href="tensors.html#cb56-35"></a><span class="co">#&gt;         [             1, 93974338147856,              0]])</span></span>
<span id="cb56-36"><a href="tensors.html#cb56-36"></a></span>
<span id="cb56-37"><a href="tensors.html#cb56-37"></a><span class="kw">message</span>(<span class="st">&quot;boolean&quot;</span>)</span>
<span id="cb56-38"><a href="tensors.html#cb56-38"></a><span class="co">#&gt; boolean</span></span>
<span id="cb56-39"><a href="tensors.html#cb56-39"></a>boolean</span>
<span id="cb56-40"><a href="tensors.html#cb56-40"></a><span class="co">#&gt; tensor([[False, False, False, False, False],</span></span>
<span id="cb56-41"><a href="tensors.html#cb56-41"></a><span class="co">#&gt;         [False, False, False, False, False],</span></span>
<span id="cb56-42"><a href="tensors.html#cb56-42"></a><span class="co">#&gt;         [False, False, False, False, False],</span></span>
<span id="cb56-43"><a href="tensors.html#cb56-43"></a><span class="co">#&gt;         [False, False, False, False, False],</span></span>
<span id="cb56-44"><a href="tensors.html#cb56-44"></a><span class="co">#&gt;         [False, False, False, False,  True]])</span></span></code></pre></div>
<p>A 4D tensor like in MNIST hand-written digits recognition dataset:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="tensors.html#cb57-1"></a>mnist_4d &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(60000L, 3L, 28L, 28L)</span>
<span id="cb57-2"><a href="tensors.html#cb57-2"></a></span>
<span id="cb57-3"><a href="tensors.html#cb57-3"></a><span class="kw">message</span>(<span class="st">&quot;size&quot;</span>)</span>
<span id="cb57-4"><a href="tensors.html#cb57-4"></a><span class="co">#&gt; size</span></span>
<span id="cb57-5"><a href="tensors.html#cb57-5"></a>mnist_4d<span class="op">$</span><span class="kw">size</span>()</span>
<span id="cb57-6"><a href="tensors.html#cb57-6"></a><span class="co">#&gt; torch.Size([60000, 3, 28, 28])</span></span>
<span id="cb57-7"><a href="tensors.html#cb57-7"></a></span>
<span id="cb57-8"><a href="tensors.html#cb57-8"></a><span class="kw">message</span>(<span class="st">&quot;length&quot;</span>)</span>
<span id="cb57-9"><a href="tensors.html#cb57-9"></a><span class="co">#&gt; length</span></span>
<span id="cb57-10"><a href="tensors.html#cb57-10"></a><span class="kw">length</span>(mnist_4d)</span>
<span id="cb57-11"><a href="tensors.html#cb57-11"></a><span class="co">#&gt; [1] 141120000</span></span>
<span id="cb57-12"><a href="tensors.html#cb57-12"></a></span>
<span id="cb57-13"><a href="tensors.html#cb57-13"></a></span>
<span id="cb57-14"><a href="tensors.html#cb57-14"></a><span class="kw">message</span>(<span class="st">&quot;shape, like in numpy&quot;</span>)</span>
<span id="cb57-15"><a href="tensors.html#cb57-15"></a><span class="co">#&gt; shape, like in numpy</span></span>
<span id="cb57-16"><a href="tensors.html#cb57-16"></a>mnist_4d<span class="op">$</span>shape</span>
<span id="cb57-17"><a href="tensors.html#cb57-17"></a><span class="co">#&gt; torch.Size([60000, 3, 28, 28])</span></span>
<span id="cb57-18"><a href="tensors.html#cb57-18"></a></span>
<span id="cb57-19"><a href="tensors.html#cb57-19"></a><span class="kw">message</span>(<span class="st">&quot;number of elements&quot;</span>)</span>
<span id="cb57-20"><a href="tensors.html#cb57-20"></a><span class="co">#&gt; number of elements</span></span>
<span id="cb57-21"><a href="tensors.html#cb57-21"></a>mnist_4d<span class="op">$</span><span class="kw">numel</span>()</span>
<span id="cb57-22"><a href="tensors.html#cb57-22"></a><span class="co">#&gt; [1] 141120000</span></span></code></pre></div>
<p>A 3D tensor:</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="tensors.html#cb58-1"></a>ft3d &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(4L, 3L, 2L)</span>
<span id="cb58-2"><a href="tensors.html#cb58-2"></a>ft3d</span>
<span id="cb58-3"><a href="tensors.html#cb58-3"></a><span class="co">#&gt; tensor([[[7.1725e-28, 4.5660e-41],</span></span>
<span id="cb58-4"><a href="tensors.html#cb58-4"></a><span class="co">#&gt;          [7.1725e-28, 4.5660e-41],</span></span>
<span id="cb58-5"><a href="tensors.html#cb58-5"></a><span class="co">#&gt;          [0.0000e+00, 0.0000e+00]],</span></span>
<span id="cb58-6"><a href="tensors.html#cb58-6"></a><span class="co">#&gt; </span></span>
<span id="cb58-7"><a href="tensors.html#cb58-7"></a><span class="co">#&gt;         [[0.0000e+00, 0.0000e+00],</span></span>
<span id="cb58-8"><a href="tensors.html#cb58-8"></a><span class="co">#&gt;          [0.0000e+00, 0.0000e+00],</span></span>
<span id="cb58-9"><a href="tensors.html#cb58-9"></a><span class="co">#&gt;          [0.0000e+00, 0.0000e+00]],</span></span>
<span id="cb58-10"><a href="tensors.html#cb58-10"></a><span class="co">#&gt; </span></span>
<span id="cb58-11"><a href="tensors.html#cb58-11"></a><span class="co">#&gt;         [[0.0000e+00, 0.0000e+00],</span></span>
<span id="cb58-12"><a href="tensors.html#cb58-12"></a><span class="co">#&gt;          [0.0000e+00, 0.0000e+00],</span></span>
<span id="cb58-13"><a href="tensors.html#cb58-13"></a><span class="co">#&gt;          [0.0000e+00, 0.0000e+00]],</span></span>
<span id="cb58-14"><a href="tensors.html#cb58-14"></a><span class="co">#&gt; </span></span>
<span id="cb58-15"><a href="tensors.html#cb58-15"></a><span class="co">#&gt;         [[0.0000e+00, 0.0000e+00],</span></span>
<span id="cb58-16"><a href="tensors.html#cb58-16"></a><span class="co">#&gt;          [0.0000e+00, 0.0000e+00],</span></span>
<span id="cb58-17"><a href="tensors.html#cb58-17"></a><span class="co">#&gt;          [0.0000e+00, 0.0000e+00]]], dtype=torch.float32)</span></span></code></pre></div>
</div>
<div id="arithmetic-of-tensors" class="section level2">
<h2><span class="header-section-number">3.2</span> Arithmetic of tensors</h2>
<div id="add-tensors" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Add tensors</h3>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="tensors.html#cb59-1"></a><span class="co"># add a scalar to a tensor</span></span>
<span id="cb59-2"><a href="tensors.html#cb59-2"></a><span class="co"># 3x5 matrix uniformly distributed between 0 and 1</span></span>
<span id="cb59-3"><a href="tensors.html#cb59-3"></a>mat0 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(3L, 5L)<span class="op">$</span><span class="kw">uniform_</span>(0L, 1L)</span>
<span id="cb59-4"><a href="tensors.html#cb59-4"></a>mat0 <span class="op">+</span><span class="st"> </span><span class="fl">0.1</span></span>
<span id="cb59-5"><a href="tensors.html#cb59-5"></a><span class="co">#&gt; tensor([[0.1477, 0.9539, 0.6283, 0.7601, 0.6835],</span></span>
<span id="cb59-6"><a href="tensors.html#cb59-6"></a><span class="co">#&gt;         [0.1423, 0.9676, 0.3412, 0.7433, 0.5402],</span></span>
<span id="cb59-7"><a href="tensors.html#cb59-7"></a><span class="co">#&gt;         [0.5570, 0.5019, 0.5169, 0.4148, 1.0495]], dtype=torch.float32)</span></span></code></pre></div>
<blockquote>
<p>The expression <code>tensor.index(m)</code> is equivalent to <code>tensor[m]</code>.</p>
</blockquote>
<p>Add an element of tensor to a tensor:</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="tensors.html#cb60-1"></a><span class="co"># fill a 3x5 matrix with 0.1</span></span>
<span id="cb60-2"><a href="tensors.html#cb60-2"></a>mat1 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(3L, 5L)<span class="op">$</span><span class="kw">uniform_</span>(<span class="fl">0.1</span>, <span class="fl">0.1</span>)</span>
<span id="cb60-3"><a href="tensors.html#cb60-3"></a><span class="co"># a vector with all ones</span></span>
<span id="cb60-4"><a href="tensors.html#cb60-4"></a>mat2 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(5L)<span class="op">$</span><span class="kw">uniform_</span>(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb60-5"><a href="tensors.html#cb60-5"></a>mat1[<span class="dv">1</span>, <span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>mat2</span>
<span id="cb60-6"><a href="tensors.html#cb60-6"></a><span class="co">#&gt; tensor([1.1000, 1.1000, 1.1000, 1.1000, 1.1000], dtype=torch.float32)</span></span></code></pre></div>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="tensors.html#cb61-1"></a><span class="co"># add two tensors</span></span>
<span id="cb61-2"><a href="tensors.html#cb61-2"></a>mat1 <span class="op">+</span><span class="st"> </span>mat0</span>
<span id="cb61-3"><a href="tensors.html#cb61-3"></a><span class="co">#&gt; tensor([[0.1477, 0.9539, 0.6283, 0.7601, 0.6835],</span></span>
<span id="cb61-4"><a href="tensors.html#cb61-4"></a><span class="co">#&gt;         [0.1423, 0.9676, 0.3412, 0.7433, 0.5402],</span></span>
<span id="cb61-5"><a href="tensors.html#cb61-5"></a><span class="co">#&gt;         [0.5570, 0.5019, 0.5169, 0.4148, 1.0495]], dtype=torch.float32)</span></span></code></pre></div>
<p>Add two tensors using the function <code>add()</code>:</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="tensors.html#cb62-1"></a><span class="co"># PyTorch add two tensors</span></span>
<span id="cb62-2"><a href="tensors.html#cb62-2"></a>x =<span class="st"> </span>torch<span class="op">$</span><span class="kw">rand</span>(5L, 4L)</span>
<span id="cb62-3"><a href="tensors.html#cb62-3"></a>y =<span class="st"> </span>torch<span class="op">$</span><span class="kw">rand</span>(5L, 4L)</span>
<span id="cb62-4"><a href="tensors.html#cb62-4"></a></span>
<span id="cb62-5"><a href="tensors.html#cb62-5"></a><span class="kw">print</span>(x<span class="op">$</span><span class="kw">add</span>(y))</span>
<span id="cb62-6"><a href="tensors.html#cb62-6"></a><span class="co">#&gt; tensor([[1.0729, 0.9561, 1.1497, 0.8166],</span></span>
<span id="cb62-7"><a href="tensors.html#cb62-7"></a><span class="co">#&gt;         [1.8610, 1.9055, 0.6484, 1.2883],</span></span>
<span id="cb62-8"><a href="tensors.html#cb62-8"></a><span class="co">#&gt;         [1.6898, 1.1211, 0.4412, 0.9007],</span></span>
<span id="cb62-9"><a href="tensors.html#cb62-9"></a><span class="co">#&gt;         [0.3447, 1.3674, 1.4276, 0.6694],</span></span>
<span id="cb62-10"><a href="tensors.html#cb62-10"></a><span class="co">#&gt;         [1.3421, 0.5942, 0.5070, 0.4228]])</span></span></code></pre></div>
<p>Add two tensors using the generic <code>+</code>:</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="tensors.html#cb63-1"></a><span class="kw">print</span>(x <span class="op">+</span><span class="st"> </span>y)</span>
<span id="cb63-2"><a href="tensors.html#cb63-2"></a><span class="co">#&gt; tensor([[1.0729, 0.9561, 1.1497, 0.8166],</span></span>
<span id="cb63-3"><a href="tensors.html#cb63-3"></a><span class="co">#&gt;         [1.8610, 1.9055, 0.6484, 1.2883],</span></span>
<span id="cb63-4"><a href="tensors.html#cb63-4"></a><span class="co">#&gt;         [1.6898, 1.1211, 0.4412, 0.9007],</span></span>
<span id="cb63-5"><a href="tensors.html#cb63-5"></a><span class="co">#&gt;         [0.3447, 1.3674, 1.4276, 0.6694],</span></span>
<span id="cb63-6"><a href="tensors.html#cb63-6"></a><span class="co">#&gt;         [1.3421, 0.5942, 0.5070, 0.4228]])</span></span></code></pre></div>
</div>
<div id="multiply-a-tensor-by-a-scalar" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Multiply a tensor by a scalar</h3>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="tensors.html#cb64-1"></a><span class="co"># Multiply tensor by scalar</span></span>
<span id="cb64-2"><a href="tensors.html#cb64-2"></a>tensor =<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(4L, <span class="dt">dtype=</span>torch<span class="op">$</span>float64)</span>
<span id="cb64-3"><a href="tensors.html#cb64-3"></a>scalar =<span class="st"> </span>np<span class="op">$</span><span class="kw">float64</span>(<span class="fl">4.321</span>)</span>
<span id="cb64-4"><a href="tensors.html#cb64-4"></a><span class="kw">print</span>(scalar)</span>
<span id="cb64-5"><a href="tensors.html#cb64-5"></a><span class="co">#&gt; [1] 4.32</span></span>
<span id="cb64-6"><a href="tensors.html#cb64-6"></a><span class="kw">print</span>(torch<span class="op">$</span><span class="kw">scalar_tensor</span>(scalar))</span>
<span id="cb64-7"><a href="tensors.html#cb64-7"></a><span class="co">#&gt; tensor(4.3210)</span></span></code></pre></div>
<p>Multiply two tensors using the function <code>mul</code>:</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="tensors.html#cb65-1"></a>(<span class="dt">prod =</span> torch<span class="op">$</span><span class="kw">mul</span>(tensor, torch<span class="op">$</span><span class="kw">scalar_tensor</span>(scalar)))</span>
<span id="cb65-2"><a href="tensors.html#cb65-2"></a><span class="co">#&gt; tensor([4.3210, 4.3210, 4.3210, 4.3210])</span></span></code></pre></div>
<p>Short version using generics</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="tensors.html#cb66-1"></a>(<span class="dt">prod =</span> tensor <span class="op">*</span><span class="st"> </span>scalar)</span>
<span id="cb66-2"><a href="tensors.html#cb66-2"></a><span class="co">#&gt; tensor([4.3210, 4.3210, 4.3210, 4.3210])</span></span></code></pre></div>
</div>
</div>
<div id="numpy-and-pytorch" class="section level2">
<h2><span class="header-section-number">3.3</span> NumPy and PyTorch</h2>
<p><code>numpy</code> has been made available as a module in <code>rTorch</code>. We can call functions from <code>numpy</code> refrerring to it as <code>np$_a_function</code>. Examples:</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="tensors.html#cb67-1"></a><span class="co"># a 2D numpy array  </span></span>
<span id="cb67-2"><a href="tensors.html#cb67-2"></a>syn0 &lt;-<span class="st"> </span>np<span class="op">$</span>random<span class="op">$</span><span class="kw">rand</span>(3L, 5L)</span>
<span id="cb67-3"><a href="tensors.html#cb67-3"></a><span class="kw">print</span>(syn0)</span>
<span id="cb67-4"><a href="tensors.html#cb67-4"></a><span class="co">#&gt;       [,1]     [,2]  [,3]  [,4]   [,5]</span></span>
<span id="cb67-5"><a href="tensors.html#cb67-5"></a><span class="co">#&gt; [1,] 0.288 0.902106 0.947 0.295 0.9721</span></span>
<span id="cb67-6"><a href="tensors.html#cb67-6"></a><span class="co">#&gt; [2,] 0.303 0.000289 0.140 0.335 0.0746</span></span>
<span id="cb67-7"><a href="tensors.html#cb67-7"></a><span class="co">#&gt; [3,] 0.114 0.681511 0.593 0.103 0.7026</span></span></code></pre></div>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="tensors.html#cb68-1"></a><span class="co"># numpy arrays of zeros</span></span>
<span id="cb68-2"><a href="tensors.html#cb68-2"></a>syn1 &lt;-<span class="st"> </span>np<span class="op">$</span><span class="kw">zeros</span>(<span class="kw">c</span>(5L, 10L))</span>
<span id="cb68-3"><a href="tensors.html#cb68-3"></a><span class="kw">print</span>(syn1)</span>
<span id="cb68-4"><a href="tensors.html#cb68-4"></a><span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]</span></span>
<span id="cb68-5"><a href="tensors.html#cb68-5"></a><span class="co">#&gt; [1,]    0    0    0    0    0    0    0    0    0     0</span></span>
<span id="cb68-6"><a href="tensors.html#cb68-6"></a><span class="co">#&gt; [2,]    0    0    0    0    0    0    0    0    0     0</span></span>
<span id="cb68-7"><a href="tensors.html#cb68-7"></a><span class="co">#&gt; [3,]    0    0    0    0    0    0    0    0    0     0</span></span>
<span id="cb68-8"><a href="tensors.html#cb68-8"></a><span class="co">#&gt; [4,]    0    0    0    0    0    0    0    0    0     0</span></span>
<span id="cb68-9"><a href="tensors.html#cb68-9"></a><span class="co">#&gt; [5,]    0    0    0    0    0    0    0    0    0     0</span></span></code></pre></div>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="tensors.html#cb69-1"></a><span class="co"># add a scalar to a numpy array</span></span>
<span id="cb69-2"><a href="tensors.html#cb69-2"></a>syn1 =<span class="st"> </span>syn1 <span class="op">+</span><span class="st"> </span><span class="fl">0.1</span></span>
<span id="cb69-3"><a href="tensors.html#cb69-3"></a><span class="kw">print</span>(syn1)</span>
<span id="cb69-4"><a href="tensors.html#cb69-4"></a><span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]</span></span>
<span id="cb69-5"><a href="tensors.html#cb69-5"></a><span class="co">#&gt; [1,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1</span></span>
<span id="cb69-6"><a href="tensors.html#cb69-6"></a><span class="co">#&gt; [2,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1</span></span>
<span id="cb69-7"><a href="tensors.html#cb69-7"></a><span class="co">#&gt; [3,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1</span></span>
<span id="cb69-8"><a href="tensors.html#cb69-8"></a><span class="co">#&gt; [4,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1</span></span>
<span id="cb69-9"><a href="tensors.html#cb69-9"></a><span class="co">#&gt; [5,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1</span></span></code></pre></div>
<div id="tuples-python-and-vectors-r" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Tuples (Python) and vectors (R)</h3>
<p>In numpy a multidimensional array needs to be defined with a tuple
in R we do it with a vector.</p>
<p>In Python, we use a tuple, <code>(5, 5)</code></p>
<div class="sourceCode" id="cb70"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="tensors.html#cb70-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb70-2"><a href="tensors.html#cb70-2"></a></span>
<span id="cb70-3"><a href="tensors.html#cb70-3"></a><span class="bu">print</span>(np.ones((<span class="dv">5</span>, <span class="dv">5</span>)))</span>
<span id="cb70-4"><a href="tensors.html#cb70-4"></a><span class="co">#&gt; [[1. 1. 1. 1. 1.]</span></span>
<span id="cb70-5"><a href="tensors.html#cb70-5"></a><span class="co">#&gt;  [1. 1. 1. 1. 1.]</span></span>
<span id="cb70-6"><a href="tensors.html#cb70-6"></a><span class="co">#&gt;  [1. 1. 1. 1. 1.]</span></span>
<span id="cb70-7"><a href="tensors.html#cb70-7"></a><span class="co">#&gt;  [1. 1. 1. 1. 1.]</span></span>
<span id="cb70-8"><a href="tensors.html#cb70-8"></a><span class="co">#&gt;  [1. 1. 1. 1. 1.]]</span></span></code></pre></div>
<p>In R, we use a vector <code>c(5L, 5L)</code>. The <code>L</code> indicates an integer.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="tensors.html#cb71-1"></a>l1 &lt;-<span class="st"> </span>np<span class="op">$</span><span class="kw">ones</span>(<span class="kw">c</span>(5L, 5L))</span>
<span id="cb71-2"><a href="tensors.html#cb71-2"></a><span class="kw">print</span>(l1)</span>
<span id="cb71-3"><a href="tensors.html#cb71-3"></a><span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5]</span></span>
<span id="cb71-4"><a href="tensors.html#cb71-4"></a><span class="co">#&gt; [1,]    1    1    1    1    1</span></span>
<span id="cb71-5"><a href="tensors.html#cb71-5"></a><span class="co">#&gt; [2,]    1    1    1    1    1</span></span>
<span id="cb71-6"><a href="tensors.html#cb71-6"></a><span class="co">#&gt; [3,]    1    1    1    1    1</span></span>
<span id="cb71-7"><a href="tensors.html#cb71-7"></a><span class="co">#&gt; [4,]    1    1    1    1    1</span></span>
<span id="cb71-8"><a href="tensors.html#cb71-8"></a><span class="co">#&gt; [5,]    1    1    1    1    1</span></span></code></pre></div>
<p>Vector-matrix multiplication in numpy:</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="tensors.html#cb72-1"></a>np<span class="op">$</span><span class="kw">dot</span>(syn0, syn1)</span>
<span id="cb72-2"><a href="tensors.html#cb72-2"></a><span class="co">#&gt;        [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]   [,8]   [,9]  [,10]</span></span>
<span id="cb72-3"><a href="tensors.html#cb72-3"></a><span class="co">#&gt; [1,] 0.3404 0.3404 0.3404 0.3404 0.3404 0.3404 0.3404 0.3404 0.3404 0.3404</span></span>
<span id="cb72-4"><a href="tensors.html#cb72-4"></a><span class="co">#&gt; [2,] 0.0853 0.0853 0.0853 0.0853 0.0853 0.0853 0.0853 0.0853 0.0853 0.0853</span></span>
<span id="cb72-5"><a href="tensors.html#cb72-5"></a><span class="co">#&gt; [3,] 0.2194 0.2194 0.2194 0.2194 0.2194 0.2194 0.2194 0.2194 0.2194 0.2194</span></span></code></pre></div>
<p>Build a numpy array from three R vectors:</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="tensors.html#cb73-1"></a>X &lt;-<span class="st"> </span>np<span class="op">$</span><span class="kw">array</span>(<span class="kw">rbind</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>), <span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>), <span class="kw">c</span>(<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>)))</span>
<span id="cb73-2"><a href="tensors.html#cb73-2"></a><span class="kw">print</span>(X)</span>
<span id="cb73-3"><a href="tensors.html#cb73-3"></a><span class="co">#&gt;      [,1] [,2] [,3]</span></span>
<span id="cb73-4"><a href="tensors.html#cb73-4"></a><span class="co">#&gt; [1,]    1    2    3</span></span>
<span id="cb73-5"><a href="tensors.html#cb73-5"></a><span class="co">#&gt; [2,]    4    5    6</span></span>
<span id="cb73-6"><a href="tensors.html#cb73-6"></a><span class="co">#&gt; [3,]    7    8    9</span></span></code></pre></div>
<p>And transpose the array:</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="tensors.html#cb74-1"></a>np<span class="op">$</span><span class="kw">transpose</span>(X)</span>
<span id="cb74-2"><a href="tensors.html#cb74-2"></a><span class="co">#&gt;      [,1] [,2] [,3]</span></span>
<span id="cb74-3"><a href="tensors.html#cb74-3"></a><span class="co">#&gt; [1,]    1    4    7</span></span>
<span id="cb74-4"><a href="tensors.html#cb74-4"></a><span class="co">#&gt; [2,]    2    5    8</span></span>
<span id="cb74-5"><a href="tensors.html#cb74-5"></a><span class="co">#&gt; [3,]    3    6    9</span></span></code></pre></div>
</div>
<div id="make-a-numpy-array-a-tensor-with-as_tensor" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Make a numpy array a tensor with <code>as_tensor()</code></h3>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="tensors.html#cb75-1"></a>a =<span class="st"> </span>np<span class="op">$</span><span class="kw">array</span>(<span class="kw">list</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>))   <span class="co"># a numpy array</span></span>
<span id="cb75-2"><a href="tensors.html#cb75-2"></a>t =<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(a)        <span class="co"># convert it to tensor</span></span>
<span id="cb75-3"><a href="tensors.html#cb75-3"></a><span class="kw">print</span>(t)</span>
<span id="cb75-4"><a href="tensors.html#cb75-4"></a><span class="co">#&gt; tensor([1., 2., 3.])</span></span></code></pre></div>
<p>We can create the tensor directly from R using <code>tensor()</code>:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="tensors.html#cb76-1"></a>torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>( <span class="dv">1</span>,  <span class="dv">2</span>,  <span class="dv">3</span>))   <span class="co"># create a tensor</span></span>
<span id="cb76-2"><a href="tensors.html#cb76-2"></a><span class="co">#&gt; tensor([1., 2., 3.])</span></span>
<span id="cb76-3"><a href="tensors.html#cb76-3"></a>t[1L]<span class="op">$</span><span class="kw">fill_</span>(<span class="op">-</span><span class="dv">1</span>)                  <span class="co"># fill element with -1</span></span>
<span id="cb76-4"><a href="tensors.html#cb76-4"></a><span class="co">#&gt; tensor(-1.)</span></span>
<span id="cb76-5"><a href="tensors.html#cb76-5"></a><span class="kw">print</span>(a)</span>
<span id="cb76-6"><a href="tensors.html#cb76-6"></a><span class="co">#&gt; [1] -1  2  3</span></span></code></pre></div>
</div>
<div id="tensor-to-array-and-viceversa" class="section level3">
<h3><span class="header-section-number">3.3.3</span> Tensor to array, and viceversa</h3>
<p>This is a very common operation in machine learning:</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="tensors.html#cb77-1"></a><span class="co"># convert tensor to a numpy array</span></span>
<span id="cb77-2"><a href="tensors.html#cb77-2"></a>a =<span class="st"> </span>torch<span class="op">$</span><span class="kw">rand</span>(5L, 4L)</span>
<span id="cb77-3"><a href="tensors.html#cb77-3"></a>b =<span class="st"> </span>a<span class="op">$</span><span class="kw">numpy</span>()</span>
<span id="cb77-4"><a href="tensors.html#cb77-4"></a><span class="kw">print</span>(b)</span>
<span id="cb77-5"><a href="tensors.html#cb77-5"></a><span class="co">#&gt;        [,1]  [,2]   [,3]  [,4]</span></span>
<span id="cb77-6"><a href="tensors.html#cb77-6"></a><span class="co">#&gt; [1,] 0.7364 0.203 0.4264 0.583</span></span>
<span id="cb77-7"><a href="tensors.html#cb77-7"></a><span class="co">#&gt; [2,] 0.0788 0.862 0.3439 0.118</span></span>
<span id="cb77-8"><a href="tensors.html#cb77-8"></a><span class="co">#&gt; [3,] 0.4154 0.689 0.2149 0.382</span></span>
<span id="cb77-9"><a href="tensors.html#cb77-9"></a><span class="co">#&gt; [4,] 0.8761 0.323 0.0173 0.919</span></span>
<span id="cb77-10"><a href="tensors.html#cb77-10"></a><span class="co">#&gt; [5,] 0.4908 0.614 0.4087 0.773</span></span></code></pre></div>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="tensors.html#cb78-1"></a><span class="co"># convert a numpy array to a tensor</span></span>
<span id="cb78-2"><a href="tensors.html#cb78-2"></a>np_a =<span class="st"> </span>np<span class="op">$</span><span class="kw">array</span>(<span class="kw">c</span>(<span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">4</span>), <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">6</span>)))</span>
<span id="cb78-3"><a href="tensors.html#cb78-3"></a>t_a =<span class="st"> </span>torch<span class="op">$</span><span class="kw">from_numpy</span>(np_a)</span>
<span id="cb78-4"><a href="tensors.html#cb78-4"></a><span class="kw">print</span>(t_a)</span>
<span id="cb78-5"><a href="tensors.html#cb78-5"></a><span class="co">#&gt; tensor([3., 4., 3., 6.])</span></span></code></pre></div>
</div>
</div>
<div id="create-tensors" class="section level2">
<h2><span class="header-section-number">3.4</span> Create tensors</h2>
<p>A random 1D tensor:</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="tensors.html#cb79-1"></a>ft1 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(np<span class="op">$</span>random<span class="op">$</span><span class="kw">rand</span>(5L))</span>
<span id="cb79-2"><a href="tensors.html#cb79-2"></a><span class="kw">print</span>(ft1)</span>
<span id="cb79-3"><a href="tensors.html#cb79-3"></a><span class="co">#&gt; tensor([0.8382, 0.6087, 0.8812, 0.5938, 0.8294], dtype=torch.float32)</span></span></code></pre></div>
<p>Force a tensor as a float of 64-bits:</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="tensors.html#cb80-1"></a>ft2 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(np<span class="op">$</span>random<span class="op">$</span><span class="kw">rand</span>(5L), <span class="dt">dtype=</span> torch<span class="op">$</span>float64)</span>
<span id="cb80-2"><a href="tensors.html#cb80-2"></a><span class="kw">print</span>(ft2)</span>
<span id="cb80-3"><a href="tensors.html#cb80-3"></a><span class="co">#&gt; tensor([0.8517, 0.0895, 0.2307, 0.2621, 0.6049])</span></span></code></pre></div>
<p>Convert the tensor to float 16-bits:</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="tensors.html#cb81-1"></a>ft2_dbl &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">as_tensor</span>(ft2, <span class="dt">dtype =</span> torch<span class="op">$</span>float16)</span>
<span id="cb81-2"><a href="tensors.html#cb81-2"></a>ft2_dbl</span>
<span id="cb81-3"><a href="tensors.html#cb81-3"></a><span class="co">#&gt; tensor([0.8516, 0.0895, 0.2307, 0.2620, 0.6050], dtype=torch.float16)</span></span></code></pre></div>
<p>Create a tensor of size (5 x 7) with uninitialized memory:</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="tensors.html#cb82-1"></a>a &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(5L, 7L)</span>
<span id="cb82-2"><a href="tensors.html#cb82-2"></a><span class="kw">print</span>(a)</span>
<span id="cb82-3"><a href="tensors.html#cb82-3"></a><span class="co">#&gt; tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,</span></span>
<span id="cb82-4"><a href="tensors.html#cb82-4"></a><span class="co">#&gt;          3.7740e-22],</span></span>
<span id="cb82-5"><a href="tensors.html#cb82-5"></a><span class="co">#&gt;         [3.0660e-41, 0.0000e+00, 0.0000e+00, 6.2242e-24, 3.0660e-41, 0.0000e+00,</span></span>
<span id="cb82-6"><a href="tensors.html#cb82-6"></a><span class="co">#&gt;          0.0000e+00],</span></span>
<span id="cb82-7"><a href="tensors.html#cb82-7"></a><span class="co">#&gt;         [1.4013e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,</span></span>
<span id="cb82-8"><a href="tensors.html#cb82-8"></a><span class="co">#&gt;          0.0000e+00],</span></span>
<span id="cb82-9"><a href="tensors.html#cb82-9"></a><span class="co">#&gt;         [0.0000e+00, 3.7740e-22, 3.0660e-41, 0.0000e+00, 0.0000e+00, 1.8334e-22,</span></span>
<span id="cb82-10"><a href="tensors.html#cb82-10"></a><span class="co">#&gt;          3.0660e-41],</span></span>
<span id="cb82-11"><a href="tensors.html#cb82-11"></a><span class="co">#&gt;         [0.0000e+00, 0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00,</span></span>
<span id="cb82-12"><a href="tensors.html#cb82-12"></a><span class="co">#&gt;          0.0000e+00]], dtype=torch.float32)</span></span></code></pre></div>
<p>Using arange to create a tensor. Start from 0:</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="tensors.html#cb83-1"></a>v =<span class="st"> </span>torch<span class="op">$</span><span class="kw">arange</span>(9L)</span>
<span id="cb83-2"><a href="tensors.html#cb83-2"></a>(<span class="dt">v =</span> v<span class="op">$</span><span class="kw">view</span>(3L, 3L))</span>
<span id="cb83-3"><a href="tensors.html#cb83-3"></a><span class="co">#&gt; tensor([[0, 1, 2],</span></span>
<span id="cb83-4"><a href="tensors.html#cb83-4"></a><span class="co">#&gt;         [3, 4, 5],</span></span>
<span id="cb83-5"><a href="tensors.html#cb83-5"></a><span class="co">#&gt;         [6, 7, 8]])</span></span></code></pre></div>
</div>
<div id="tensor-resizing" class="section level2">
<h2><span class="header-section-number">3.5</span> Tensor resizing</h2>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="tensors.html#cb84-1"></a>x =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(2L, 3L)            <span class="co"># Size 2x3</span></span>
<span id="cb84-2"><a href="tensors.html#cb84-2"></a>y =<span class="st"> </span>x<span class="op">$</span><span class="kw">view</span>(6L)                     <span class="co"># Resize x to size 6</span></span>
<span id="cb84-3"><a href="tensors.html#cb84-3"></a>z =<span class="st"> </span>x<span class="op">$</span><span class="kw">view</span>(<span class="op">-</span>1L, 2L)                <span class="co"># Size 3x2</span></span>
<span id="cb84-4"><a href="tensors.html#cb84-4"></a><span class="kw">print</span>(y)</span>
<span id="cb84-5"><a href="tensors.html#cb84-5"></a><span class="co">#&gt; tensor([-0.2870, -0.1020, -0.4349, -0.3872,  1.8473, -2.1595])</span></span>
<span id="cb84-6"><a href="tensors.html#cb84-6"></a><span class="kw">print</span>(z)</span>
<span id="cb84-7"><a href="tensors.html#cb84-7"></a><span class="co">#&gt; tensor([[-0.2870, -0.1020],</span></span>
<span id="cb84-8"><a href="tensors.html#cb84-8"></a><span class="co">#&gt;         [-0.4349, -0.3872],</span></span>
<span id="cb84-9"><a href="tensors.html#cb84-9"></a><span class="co">#&gt;         [ 1.8473, -2.1595]])</span></span></code></pre></div>
<p>Reproduce this tensor:</p>
<pre><code> 0 1 2
 3 4 5
 6 7 8</code></pre>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="tensors.html#cb86-1"></a>v =<span class="st"> </span>torch<span class="op">$</span><span class="kw">arange</span>(9L)</span>
<span id="cb86-2"><a href="tensors.html#cb86-2"></a>(<span class="dt">v =</span> v<span class="op">$</span><span class="kw">view</span>(3L, 3L))</span>
<span id="cb86-3"><a href="tensors.html#cb86-3"></a><span class="co">#&gt; tensor([[0, 1, 2],</span></span>
<span id="cb86-4"><a href="tensors.html#cb86-4"></a><span class="co">#&gt;         [3, 4, 5],</span></span>
<span id="cb86-5"><a href="tensors.html#cb86-5"></a><span class="co">#&gt;         [6, 7, 8]])</span></span></code></pre></div>
<div id="concatenate-tensors" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Concatenate tensors</h3>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="tensors.html#cb87-1"></a>x =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(2L, 3L)</span>
<span id="cb87-2"><a href="tensors.html#cb87-2"></a><span class="kw">print</span>(x)</span>
<span id="cb87-3"><a href="tensors.html#cb87-3"></a><span class="co">#&gt; tensor([[-0.7548,  0.1692,  0.9823],</span></span>
<span id="cb87-4"><a href="tensors.html#cb87-4"></a><span class="co">#&gt;         [-0.8146,  1.5708, -0.1614]])</span></span></code></pre></div>
<p>Concatenate tensors by <code>dim=0</code>:</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="tensors.html#cb88-1"></a>torch<span class="op">$</span><span class="kw">cat</span>(<span class="kw">list</span>(x, x, x), 0L)</span>
<span id="cb88-2"><a href="tensors.html#cb88-2"></a><span class="co">#&gt; tensor([[-0.7548,  0.1692,  0.9823],</span></span>
<span id="cb88-3"><a href="tensors.html#cb88-3"></a><span class="co">#&gt;         [-0.8146,  1.5708, -0.1614],</span></span>
<span id="cb88-4"><a href="tensors.html#cb88-4"></a><span class="co">#&gt;         [-0.7548,  0.1692,  0.9823],</span></span>
<span id="cb88-5"><a href="tensors.html#cb88-5"></a><span class="co">#&gt;         [-0.8146,  1.5708, -0.1614],</span></span>
<span id="cb88-6"><a href="tensors.html#cb88-6"></a><span class="co">#&gt;         [-0.7548,  0.1692,  0.9823],</span></span>
<span id="cb88-7"><a href="tensors.html#cb88-7"></a><span class="co">#&gt;         [-0.8146,  1.5708, -0.1614]])</span></span></code></pre></div>
<p>Concatenate tensors by <code>dim=1</code>:</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="tensors.html#cb89-1"></a>torch<span class="op">$</span><span class="kw">cat</span>(<span class="kw">list</span>(x, x, x), 1L)</span>
<span id="cb89-2"><a href="tensors.html#cb89-2"></a><span class="co">#&gt; tensor([[-0.7548,  0.1692,  0.9823, -0.7548,  0.1692,  0.9823, -0.7548,  0.1692,</span></span>
<span id="cb89-3"><a href="tensors.html#cb89-3"></a><span class="co">#&gt;           0.9823],</span></span>
<span id="cb89-4"><a href="tensors.html#cb89-4"></a><span class="co">#&gt;         [-0.8146,  1.5708, -0.1614, -0.8146,  1.5708, -0.1614, -0.8146,  1.5708,</span></span>
<span id="cb89-5"><a href="tensors.html#cb89-5"></a><span class="co">#&gt;          -0.1614]])</span></span></code></pre></div>
</div>
</div>
<div id="reshape-tensors" class="section level2">
<h2><span class="header-section-number">3.6</span> Reshape tensors</h2>
<div id="with-function-chunk" class="section level3">
<h3><span class="header-section-number">3.6.1</span> With function <code>chunk()</code>:</h3>
<p>Let’s say this is an image tensor with the 3-channels and 28x28 pixels</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="tensors.html#cb90-1"></a><span class="co"># ----- Reshape tensors -----</span></span>
<span id="cb90-2"><a href="tensors.html#cb90-2"></a>img &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(3L, 28L, 28L)  <span class="co"># Create the tensor of ones</span></span>
<span id="cb90-3"><a href="tensors.html#cb90-3"></a><span class="kw">print</span>(img<span class="op">$</span><span class="kw">size</span>())</span>
<span id="cb90-4"><a href="tensors.html#cb90-4"></a><span class="co">#&gt; torch.Size([3, 28, 28])</span></span></code></pre></div>
<p>On the first dimension <code>dim = 0L</code>, reshape the tensor:</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="tensors.html#cb91-1"></a>img_chunks &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">chunk</span>(img, <span class="dt">chunks =</span> 3L, <span class="dt">dim =</span> 0L)</span>
<span id="cb91-2"><a href="tensors.html#cb91-2"></a><span class="kw">print</span>(<span class="kw">length</span>(img_chunks))</span>
<span id="cb91-3"><a href="tensors.html#cb91-3"></a><span class="co">#&gt; [1] 3</span></span></code></pre></div>
<p>The first chunk member:</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="tensors.html#cb92-1"></a><span class="co"># 1st chunk member</span></span>
<span id="cb92-2"><a href="tensors.html#cb92-2"></a>img_chunk &lt;-<span class="st"> </span>img_chunks[[<span class="dv">1</span>]]</span>
<span id="cb92-3"><a href="tensors.html#cb92-3"></a><span class="kw">print</span>(img_chunk<span class="op">$</span><span class="kw">size</span>())</span>
<span id="cb92-4"><a href="tensors.html#cb92-4"></a><span class="co">#&gt; torch.Size([1, 28, 28])</span></span>
<span id="cb92-5"><a href="tensors.html#cb92-5"></a><span class="kw">print</span>(img_chunk<span class="op">$</span><span class="kw">sum</span>())      <span class="co"># if the tensor had all ones, what is the sum?</span></span>
<span id="cb92-6"><a href="tensors.html#cb92-6"></a><span class="co">#&gt; tensor(784.)</span></span></code></pre></div>
<p>The second chunk member:</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="tensors.html#cb93-1"></a><span class="co"># 2nd chunk member</span></span>
<span id="cb93-2"><a href="tensors.html#cb93-2"></a>img_chunk &lt;-<span class="st"> </span>img_chunks[[<span class="dv">2</span>]]</span>
<span id="cb93-3"><a href="tensors.html#cb93-3"></a><span class="kw">print</span>(img_chunk<span class="op">$</span><span class="kw">size</span>())</span>
<span id="cb93-4"><a href="tensors.html#cb93-4"></a><span class="co">#&gt; torch.Size([1, 28, 28])</span></span>
<span id="cb93-5"><a href="tensors.html#cb93-5"></a><span class="kw">print</span>(img_chunk<span class="op">$</span><span class="kw">sum</span>())        <span class="co"># if the tensor had all ones, what is the sum?</span></span>
<span id="cb93-6"><a href="tensors.html#cb93-6"></a><span class="co">#&gt; tensor(784.)</span></span></code></pre></div>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="tensors.html#cb94-1"></a><span class="co"># 3rd chunk member</span></span>
<span id="cb94-2"><a href="tensors.html#cb94-2"></a>img_chunk &lt;-<span class="st"> </span>img_chunks[[<span class="dv">3</span>]]</span>
<span id="cb94-3"><a href="tensors.html#cb94-3"></a><span class="kw">print</span>(img_chunk<span class="op">$</span><span class="kw">size</span>())</span>
<span id="cb94-4"><a href="tensors.html#cb94-4"></a><span class="co">#&gt; torch.Size([1, 28, 28])</span></span>
<span id="cb94-5"><a href="tensors.html#cb94-5"></a><span class="kw">print</span>(img_chunk<span class="op">$</span><span class="kw">sum</span>())        <span class="co"># if the tensor had all ones, what is the sum?</span></span>
<span id="cb94-6"><a href="tensors.html#cb94-6"></a><span class="co">#&gt; tensor(784.)</span></span></code></pre></div>
</div>
<div id="with-index_select" class="section level3">
<h3><span class="header-section-number">3.6.2</span> With <code>index_select()</code>:</h3>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="tensors.html#cb95-1"></a>img &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(3L, 28L, 28L)  <span class="co"># Create the tensor of ones</span></span></code></pre></div>
<p>This is the layer 1:</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="tensors.html#cb96-1"></a><span class="co"># index_select. get layer 1</span></span>
<span id="cb96-2"><a href="tensors.html#cb96-2"></a>indices =<span class="st"> </span>torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">c</span>(0L))</span>
<span id="cb96-3"><a href="tensors.html#cb96-3"></a>img_layer &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">index_select</span>(img, <span class="dt">dim =</span> 0L, <span class="dt">index =</span> indices)</span></code></pre></div>
<p>The size of the layer:</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="tensors.html#cb97-1"></a><span class="kw">print</span>(img_layer<span class="op">$</span><span class="kw">size</span>())</span>
<span id="cb97-2"><a href="tensors.html#cb97-2"></a><span class="co">#&gt; torch.Size([1, 28, 28])</span></span></code></pre></div>
<p>The sum of all elements in that layer:</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="tensors.html#cb98-1"></a><span class="kw">print</span>(img_layer<span class="op">$</span><span class="kw">sum</span>())</span>
<span id="cb98-2"><a href="tensors.html#cb98-2"></a><span class="co">#&gt; tensor(784.)</span></span></code></pre></div>
<p>This is the layer 2:</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="tensors.html#cb99-1"></a><span class="co"># index_select. get layer 2</span></span>
<span id="cb99-2"><a href="tensors.html#cb99-2"></a>indices =<span class="st"> </span>torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">c</span>(1L))</span>
<span id="cb99-3"><a href="tensors.html#cb99-3"></a>img_layer &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">index_select</span>(img, <span class="dt">dim =</span> 0L, <span class="dt">index =</span> indices)</span>
<span id="cb99-4"><a href="tensors.html#cb99-4"></a><span class="kw">print</span>(img_layer<span class="op">$</span><span class="kw">size</span>())</span>
<span id="cb99-5"><a href="tensors.html#cb99-5"></a><span class="co">#&gt; torch.Size([1, 28, 28])</span></span>
<span id="cb99-6"><a href="tensors.html#cb99-6"></a><span class="kw">print</span>(img_layer<span class="op">$</span><span class="kw">sum</span>())</span>
<span id="cb99-7"><a href="tensors.html#cb99-7"></a><span class="co">#&gt; tensor(784.)</span></span></code></pre></div>
<p>This is the layer 3:</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="tensors.html#cb100-1"></a><span class="co"># index_select. get layer 3</span></span>
<span id="cb100-2"><a href="tensors.html#cb100-2"></a>indices =<span class="st"> </span>torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">c</span>(2L))</span>
<span id="cb100-3"><a href="tensors.html#cb100-3"></a>img_layer &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">index_select</span>(img, <span class="dt">dim =</span> 0L, <span class="dt">index =</span> indices)</span>
<span id="cb100-4"><a href="tensors.html#cb100-4"></a><span class="kw">print</span>(img_layer<span class="op">$</span><span class="kw">size</span>())</span>
<span id="cb100-5"><a href="tensors.html#cb100-5"></a><span class="co">#&gt; torch.Size([1, 28, 28])</span></span>
<span id="cb100-6"><a href="tensors.html#cb100-6"></a><span class="kw">print</span>(img_layer<span class="op">$</span><span class="kw">sum</span>())</span>
<span id="cb100-7"><a href="tensors.html#cb100-7"></a><span class="co">#&gt; tensor(784.)</span></span></code></pre></div>
</div>
</div>
<div id="special-tensors" class="section level2">
<h2><span class="header-section-number">3.7</span> Special tensors</h2>
<div id="identity-matrix" class="section level3">
<h3><span class="header-section-number">3.7.1</span> Identity matrix</h3>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="tensors.html#cb101-1"></a><span class="co"># identity matrix</span></span>
<span id="cb101-2"><a href="tensors.html#cb101-2"></a>eye =<span class="st"> </span>torch<span class="op">$</span><span class="kw">eye</span>(3L)              <span class="co"># Create an identity 3x3 tensor</span></span>
<span id="cb101-3"><a href="tensors.html#cb101-3"></a><span class="kw">print</span>(eye)</span>
<span id="cb101-4"><a href="tensors.html#cb101-4"></a><span class="co">#&gt; tensor([[1., 0., 0.],</span></span>
<span id="cb101-5"><a href="tensors.html#cb101-5"></a><span class="co">#&gt;         [0., 1., 0.],</span></span>
<span id="cb101-6"><a href="tensors.html#cb101-6"></a><span class="co">#&gt;         [0., 0., 1.]])</span></span></code></pre></div>
</div>
<div id="ones" class="section level3">
<h3><span class="header-section-number">3.7.2</span> Ones</h3>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="tensors.html#cb102-1"></a>(<span class="dt">v =</span> torch<span class="op">$</span><span class="kw">ones</span>(10L))              <span class="co"># A tensor of size 10 containing all ones</span></span>
<span id="cb102-2"><a href="tensors.html#cb102-2"></a><span class="co">#&gt; tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])</span></span>
<span id="cb102-3"><a href="tensors.html#cb102-3"></a>(<span class="dt">v =</span> torch<span class="op">$</span><span class="kw">ones</span>(2L, 1L, 2L, 1L))      <span class="co"># Size 2x1x2x1</span></span>
<span id="cb102-4"><a href="tensors.html#cb102-4"></a><span class="co">#&gt; tensor([[[[1.],</span></span>
<span id="cb102-5"><a href="tensors.html#cb102-5"></a><span class="co">#&gt;           [1.]]],</span></span>
<span id="cb102-6"><a href="tensors.html#cb102-6"></a><span class="co">#&gt; </span></span>
<span id="cb102-7"><a href="tensors.html#cb102-7"></a><span class="co">#&gt; </span></span>
<span id="cb102-8"><a href="tensors.html#cb102-8"></a><span class="co">#&gt;         [[[1.],</span></span>
<span id="cb102-9"><a href="tensors.html#cb102-9"></a><span class="co">#&gt;           [1.]]]])</span></span></code></pre></div>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="tensors.html#cb103-1"></a>v =<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones_like</span>(eye)     <span class="co"># A tensor with same shape as eye. Fill it with 1.</span></span>
<span id="cb103-2"><a href="tensors.html#cb103-2"></a>v</span>
<span id="cb103-3"><a href="tensors.html#cb103-3"></a><span class="co">#&gt; tensor([[1., 1., 1.],</span></span>
<span id="cb103-4"><a href="tensors.html#cb103-4"></a><span class="co">#&gt;         [1., 1., 1.],</span></span>
<span id="cb103-5"><a href="tensors.html#cb103-5"></a><span class="co">#&gt;         [1., 1., 1.]])</span></span></code></pre></div>
</div>
<div id="zeros" class="section level3">
<h3><span class="header-section-number">3.7.3</span> Zeros</h3>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="tensors.html#cb104-1"></a>(<span class="dt">z =</span> torch<span class="op">$</span><span class="kw">zeros</span>(10L))             <span class="co"># A tensor of size 10 containing all zeros</span></span>
<span id="cb104-2"><a href="tensors.html#cb104-2"></a><span class="co">#&gt; tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])</span></span></code></pre></div>
</div>
</div>
<div id="tensor-fill" class="section level2">
<h2><span class="header-section-number">3.8</span> Tensor fill</h2>
<p>On this tensor:</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="tensors.html#cb105-1"></a>(<span class="dt">v =</span> torch<span class="op">$</span><span class="kw">ones</span>(3L, 3L))</span>
<span id="cb105-2"><a href="tensors.html#cb105-2"></a><span class="co">#&gt; tensor([[1., 1., 1.],</span></span>
<span id="cb105-3"><a href="tensors.html#cb105-3"></a><span class="co">#&gt;         [1., 1., 1.],</span></span>
<span id="cb105-4"><a href="tensors.html#cb105-4"></a><span class="co">#&gt;         [1., 1., 1.]])</span></span></code></pre></div>
<p>Fill row 1 with 2s:</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="tensors.html#cb106-1"></a>v[1L, ]<span class="op">$</span><span class="kw">fill_</span>(2L)         </span>
<span id="cb106-2"><a href="tensors.html#cb106-2"></a><span class="co">#&gt; tensor([2., 2., 2.])</span></span>
<span id="cb106-3"><a href="tensors.html#cb106-3"></a><span class="kw">print</span>(v)</span>
<span id="cb106-4"><a href="tensors.html#cb106-4"></a><span class="co">#&gt; tensor([[2., 2., 2.],</span></span>
<span id="cb106-5"><a href="tensors.html#cb106-5"></a><span class="co">#&gt;         [1., 1., 1.],</span></span>
<span id="cb106-6"><a href="tensors.html#cb106-6"></a><span class="co">#&gt;         [1., 1., 1.]])</span></span></code></pre></div>
<p>Fill row 2 with 3s:</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="tensors.html#cb107-1"></a>v[2L, ]<span class="op">$</span><span class="kw">fill_</span>(3L)       </span>
<span id="cb107-2"><a href="tensors.html#cb107-2"></a><span class="co">#&gt; tensor([3., 3., 3.])</span></span>
<span id="cb107-3"><a href="tensors.html#cb107-3"></a><span class="kw">print</span>(v)</span>
<span id="cb107-4"><a href="tensors.html#cb107-4"></a><span class="co">#&gt; tensor([[2., 2., 2.],</span></span>
<span id="cb107-5"><a href="tensors.html#cb107-5"></a><span class="co">#&gt;         [3., 3., 3.],</span></span>
<span id="cb107-6"><a href="tensors.html#cb107-6"></a><span class="co">#&gt;         [1., 1., 1.]])</span></span></code></pre></div>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="tensors.html#cb108-1"></a><span class="co"># Initialize Tensor with a range of value</span></span>
<span id="cb108-2"><a href="tensors.html#cb108-2"></a>v =<span class="st"> </span>torch<span class="op">$</span><span class="kw">arange</span>(10L)             <span class="co"># similar to range(5) but creating a Tensor</span></span>
<span id="cb108-3"><a href="tensors.html#cb108-3"></a>(<span class="dt">v =</span> torch<span class="op">$</span><span class="kw">arange</span>(0L, 10L, <span class="dt">step =</span> 1L))  <span class="co"># Size 5. Similar to range(0, 5, 1)</span></span>
<span id="cb108-4"><a href="tensors.html#cb108-4"></a><span class="co">#&gt; tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</span></span></code></pre></div>
<div id="initialize-a-linear-or-log-scale-tensor" class="section level3">
<h3><span class="header-section-number">3.8.1</span> Initialize a linear or log scale Tensor</h3>
<p>Create a tensor with 10 linear points for (1, 10) inclusive:</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="tensors.html#cb109-1"></a>(<span class="dt">v =</span> torch<span class="op">$</span><span class="kw">linspace</span>(1L, 10L, <span class="dt">steps =</span> 10L)) </span>
<span id="cb109-2"><a href="tensors.html#cb109-2"></a><span class="co">#&gt; tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])</span></span></code></pre></div>
<p>Create a tensor with 10 logarithmic points for (1, 10) inclusive:</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="tensors.html#cb110-1"></a>(<span class="dt">v =</span> torch<span class="op">$</span><span class="kw">logspace</span>(<span class="dt">start=</span><span class="op">-</span>10L, <span class="dt">end =</span> 10L, <span class="dt">steps =</span> 5L)) </span>
<span id="cb110-2"><a href="tensors.html#cb110-2"></a><span class="co">#&gt; tensor([1.0000e-10, 1.0000e-05, 1.0000e+00, 1.0000e+05, 1.0000e+10])</span></span></code></pre></div>
</div>
<div id="inplace-out-of-place" class="section level3">
<h3><span class="header-section-number">3.8.2</span> Inplace / Out-of-place</h3>
<p>On this uninitialized tensor:</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="tensors.html#cb111-1"></a>(a &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(5L, 7L))</span>
<span id="cb111-2"><a href="tensors.html#cb111-2"></a><span class="co">#&gt; tensor([[0., 0., 0., 0., 0., 0., 0.],</span></span>
<span id="cb111-3"><a href="tensors.html#cb111-3"></a><span class="co">#&gt;         [0., 0., 0., 0., 0., 0., 0.],</span></span>
<span id="cb111-4"><a href="tensors.html#cb111-4"></a><span class="co">#&gt;         [0., 0., 0., 0., 0., 0., 0.],</span></span>
<span id="cb111-5"><a href="tensors.html#cb111-5"></a><span class="co">#&gt;         [0., 0., 0., 0., 0., 0., 0.],</span></span>
<span id="cb111-6"><a href="tensors.html#cb111-6"></a><span class="co">#&gt;         [0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float32)</span></span></code></pre></div>
<p>Fill the tensor with the value 3.5:</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="tensors.html#cb112-1"></a>a<span class="op">$</span><span class="kw">fill_</span>(<span class="fl">3.5</span>)</span>
<span id="cb112-2"><a href="tensors.html#cb112-2"></a><span class="co">#&gt; tensor([[3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],</span></span>
<span id="cb112-3"><a href="tensors.html#cb112-3"></a><span class="co">#&gt;         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],</span></span>
<span id="cb112-4"><a href="tensors.html#cb112-4"></a><span class="co">#&gt;         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],</span></span>
<span id="cb112-5"><a href="tensors.html#cb112-5"></a><span class="co">#&gt;         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],</span></span>
<span id="cb112-6"><a href="tensors.html#cb112-6"></a><span class="co">#&gt;         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000]],</span></span>
<span id="cb112-7"><a href="tensors.html#cb112-7"></a><span class="co">#&gt;        dtype=torch.float32)</span></span></code></pre></div>
<p>Add a scalar to the tensor:</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="tensors.html#cb113-1"></a>b &lt;-<span class="st"> </span>a<span class="op">$</span><span class="kw">add</span>(<span class="fl">4.0</span>)</span></code></pre></div>
<p>The tensor <code>a</code> is still filled with 3.5.
A new tensor <code>b</code> is returned with values 3.5 + 4.0 = 7.5</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="tensors.html#cb114-1"></a><span class="kw">print</span>(a)</span>
<span id="cb114-2"><a href="tensors.html#cb114-2"></a><span class="co">#&gt; tensor([[3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],</span></span>
<span id="cb114-3"><a href="tensors.html#cb114-3"></a><span class="co">#&gt;         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],</span></span>
<span id="cb114-4"><a href="tensors.html#cb114-4"></a><span class="co">#&gt;         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],</span></span>
<span id="cb114-5"><a href="tensors.html#cb114-5"></a><span class="co">#&gt;         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],</span></span>
<span id="cb114-6"><a href="tensors.html#cb114-6"></a><span class="co">#&gt;         [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000]],</span></span>
<span id="cb114-7"><a href="tensors.html#cb114-7"></a><span class="co">#&gt;        dtype=torch.float32)</span></span>
<span id="cb114-8"><a href="tensors.html#cb114-8"></a><span class="kw">print</span>(b)</span>
<span id="cb114-9"><a href="tensors.html#cb114-9"></a><span class="co">#&gt; tensor([[7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000],</span></span>
<span id="cb114-10"><a href="tensors.html#cb114-10"></a><span class="co">#&gt;         [7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000],</span></span>
<span id="cb114-11"><a href="tensors.html#cb114-11"></a><span class="co">#&gt;         [7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000],</span></span>
<span id="cb114-12"><a href="tensors.html#cb114-12"></a><span class="co">#&gt;         [7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000],</span></span>
<span id="cb114-13"><a href="tensors.html#cb114-13"></a><span class="co">#&gt;         [7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000, 7.5000]],</span></span>
<span id="cb114-14"><a href="tensors.html#cb114-14"></a><span class="co">#&gt;        dtype=torch.float32)</span></span></code></pre></div>
</div>
</div>
<div id="access-to-tensor-elements" class="section level2">
<h2><span class="header-section-number">3.9</span> Access to tensor elements</h2>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="tensors.html#cb115-1"></a><span class="co"># replace an element at position 0, 0</span></span>
<span id="cb115-2"><a href="tensors.html#cb115-2"></a>(<span class="dt">new_tensor =</span> torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">list</span>(<span class="dv">3</span>, <span class="dv">4</span>))))</span>
<span id="cb115-3"><a href="tensors.html#cb115-3"></a><span class="co">#&gt; tensor([[1., 2.],</span></span>
<span id="cb115-4"><a href="tensors.html#cb115-4"></a><span class="co">#&gt;         [3., 4.]])</span></span></code></pre></div>
<p>Print element at position <code>1,1</code>:</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="tensors.html#cb116-1"></a><span class="kw">print</span>(new_tensor[1L, 1L])</span>
<span id="cb116-2"><a href="tensors.html#cb116-2"></a><span class="co">#&gt; tensor(1.)</span></span></code></pre></div>
<p>Fill element at position <code>1,1</code> with 5:</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="tensors.html#cb117-1"></a>new_tensor[1L, 1L]<span class="op">$</span><span class="kw">fill_</span>(<span class="dv">5</span>)</span>
<span id="cb117-2"><a href="tensors.html#cb117-2"></a><span class="co">#&gt; tensor(5.)</span></span></code></pre></div>
<p>Show the modified tensor:</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="tensors.html#cb118-1"></a><span class="kw">print</span>(new_tensor)   <span class="co"># tensor([[ 5.,  2.],[ 3.,  4.]])</span></span>
<span id="cb118-2"><a href="tensors.html#cb118-2"></a><span class="co">#&gt; tensor([[5., 2.],</span></span>
<span id="cb118-3"><a href="tensors.html#cb118-3"></a><span class="co">#&gt;         [3., 4.]])</span></span></code></pre></div>
<p>Access an element at position <code>1, 0</code>:</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="tensors.html#cb119-1"></a><span class="kw">print</span>(new_tensor[2L, 1L])           <span class="co"># tensor([ 3.])</span></span>
<span id="cb119-2"><a href="tensors.html#cb119-2"></a><span class="co">#&gt; tensor(3.)</span></span>
<span id="cb119-3"><a href="tensors.html#cb119-3"></a><span class="kw">print</span>(new_tensor[2L, 1L]<span class="op">$</span><span class="kw">item</span>())    <span class="co"># 3.</span></span>
<span id="cb119-4"><a href="tensors.html#cb119-4"></a><span class="co">#&gt; [1] 3</span></span></code></pre></div>
<div id="using-indices-to-access-elements" class="section level3">
<h3><span class="header-section-number">3.9.1</span> Using indices to access elements</h3>
<p>On this tensor:</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="tensors.html#cb120-1"></a>x =<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(3L, 4L)</span>
<span id="cb120-2"><a href="tensors.html#cb120-2"></a><span class="kw">print</span>(x)</span>
<span id="cb120-3"><a href="tensors.html#cb120-3"></a><span class="co">#&gt; tensor([[-1.4743, -0.3197, -0.0375,  0.5874],</span></span>
<span id="cb120-4"><a href="tensors.html#cb120-4"></a><span class="co">#&gt;         [-0.3592,  0.5674,  0.7765,  0.8658],</span></span>
<span id="cb120-5"><a href="tensors.html#cb120-5"></a><span class="co">#&gt;         [ 0.2654, -0.5901, -0.6315, -1.6710]])</span></span></code></pre></div>
<p>Select indices, <code>dim=0</code>:</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="tensors.html#cb121-1"></a>indices =<span class="st"> </span>torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(0L, 2L))</span>
<span id="cb121-2"><a href="tensors.html#cb121-2"></a>torch<span class="op">$</span><span class="kw">index_select</span>(x, 0L, indices)</span>
<span id="cb121-3"><a href="tensors.html#cb121-3"></a><span class="co">#&gt; tensor([[-1.4743, -0.3197, -0.0375,  0.5874],</span></span>
<span id="cb121-4"><a href="tensors.html#cb121-4"></a><span class="co">#&gt;         [ 0.2654, -0.5901, -0.6315, -1.6710]])</span></span></code></pre></div>
<p>Select indices, <code>dim=1</code>:</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="tensors.html#cb122-1"></a>torch<span class="op">$</span><span class="kw">index_select</span>(x, 1L, indices)</span>
<span id="cb122-2"><a href="tensors.html#cb122-2"></a><span class="co">#&gt; tensor([[-1.4743, -0.0375],</span></span>
<span id="cb122-3"><a href="tensors.html#cb122-3"></a><span class="co">#&gt;         [-0.3592,  0.7765],</span></span>
<span id="cb122-4"><a href="tensors.html#cb122-4"></a><span class="co">#&gt;         [ 0.2654, -0.6315]])</span></span></code></pre></div>
</div>
<div id="using-the-take-function" class="section level3">
<h3><span class="header-section-number">3.9.2</span> Using the <code>take</code> function</h3>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="tensors.html#cb123-1"></a><span class="co"># Take by indices</span></span>
<span id="cb123-2"><a href="tensors.html#cb123-2"></a>src =<span class="st"> </span>torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">5</span>),</span>
<span id="cb123-3"><a href="tensors.html#cb123-3"></a>                        <span class="kw">list</span>(<span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>)) )</span>
<span id="cb123-4"><a href="tensors.html#cb123-4"></a><span class="kw">print</span>(src)</span>
<span id="cb123-5"><a href="tensors.html#cb123-5"></a><span class="co">#&gt; tensor([[4., 3., 5.],</span></span>
<span id="cb123-6"><a href="tensors.html#cb123-6"></a><span class="co">#&gt;         [6., 7., 8.]])</span></span>
<span id="cb123-7"><a href="tensors.html#cb123-7"></a><span class="kw">print</span>( torch<span class="op">$</span><span class="kw">take</span>(src, torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(0L, 2L, 5L))) )</span>
<span id="cb123-8"><a href="tensors.html#cb123-8"></a><span class="co">#&gt; tensor([4., 5., 8.])</span></span></code></pre></div>
</div>
</div>
<div id="other-tensor-operations" class="section level2">
<h2><span class="header-section-number">3.10</span> Other tensor operations</h2>
<div id="cross-product" class="section level3">
<h3><span class="header-section-number">3.10.1</span> Cross product</h3>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="tensors.html#cb124-1"></a>m1 =<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(3L, 5L)</span>
<span id="cb124-2"><a href="tensors.html#cb124-2"></a>m2 =<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(3L, 5L)</span>
<span id="cb124-3"><a href="tensors.html#cb124-3"></a>v1 =<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(3L)</span>
<span id="cb124-4"><a href="tensors.html#cb124-4"></a><span class="co"># Cross product</span></span>
<span id="cb124-5"><a href="tensors.html#cb124-5"></a><span class="co"># Size 3x5</span></span>
<span id="cb124-6"><a href="tensors.html#cb124-6"></a>(<span class="dt">r =</span> torch<span class="op">$</span><span class="kw">cross</span>(m1, m2))</span>
<span id="cb124-7"><a href="tensors.html#cb124-7"></a><span class="co">#&gt; tensor([[0., 0., 0., 0., 0.],</span></span>
<span id="cb124-8"><a href="tensors.html#cb124-8"></a><span class="co">#&gt;         [0., 0., 0., 0., 0.],</span></span>
<span id="cb124-9"><a href="tensors.html#cb124-9"></a><span class="co">#&gt;         [0., 0., 0., 0., 0.]])</span></span></code></pre></div>
</div>
<div id="dot-product" class="section level3">
<h3><span class="header-section-number">3.10.2</span> Dot product</h3>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="tensors.html#cb125-1"></a><span class="co"># Dot product of 2 tensors</span></span>
<span id="cb125-2"><a href="tensors.html#cb125-2"></a><span class="co"># Dot product of 2 tensors</span></span>
<span id="cb125-3"><a href="tensors.html#cb125-3"></a></span>
<span id="cb125-4"><a href="tensors.html#cb125-4"></a>p &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">list</span>(4L, 2L))</span>
<span id="cb125-5"><a href="tensors.html#cb125-5"></a>q &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">Tensor</span>(<span class="kw">list</span>(3L, 1L))                   </span>
<span id="cb125-6"><a href="tensors.html#cb125-6"></a></span>
<span id="cb125-7"><a href="tensors.html#cb125-7"></a>(<span class="dt">r =</span> torch<span class="op">$</span><span class="kw">dot</span>(p, q)) <span class="co"># 14</span></span>
<span id="cb125-8"><a href="tensors.html#cb125-8"></a><span class="co">#&gt; tensor(14.)</span></span>
<span id="cb125-9"><a href="tensors.html#cb125-9"></a>(r &lt;-<span class="st"> </span>p <span class="op">%.*%</span><span class="st"> </span>q)</span>
<span id="cb125-10"><a href="tensors.html#cb125-10"></a><span class="co">#&gt; tensor(14.)</span></span></code></pre></div>
</div>
</div>
<div id="logical-operations" class="section level2">
<h2><span class="header-section-number">3.11</span> Logical operations</h2>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="tensors.html#cb126-1"></a>m0 =<span class="st"> </span>torch<span class="op">$</span><span class="kw">zeros</span>(3L, 5L)</span>
<span id="cb126-2"><a href="tensors.html#cb126-2"></a>m1 =<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(3L, 5L)</span>
<span id="cb126-3"><a href="tensors.html#cb126-3"></a>m2 =<span class="st"> </span>torch<span class="op">$</span><span class="kw">eye</span>(3L, 5L)</span>
<span id="cb126-4"><a href="tensors.html#cb126-4"></a></span>
<span id="cb126-5"><a href="tensors.html#cb126-5"></a><span class="kw">print</span>(m1 <span class="op">==</span><span class="st"> </span>m0)</span>
<span id="cb126-6"><a href="tensors.html#cb126-6"></a><span class="co">#&gt; tensor([[False, False, False, False, False],</span></span>
<span id="cb126-7"><a href="tensors.html#cb126-7"></a><span class="co">#&gt;         [False, False, False, False, False],</span></span>
<span id="cb126-8"><a href="tensors.html#cb126-8"></a><span class="co">#&gt;         [False, False, False, False, False]])</span></span></code></pre></div>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="tensors.html#cb127-1"></a><span class="kw">print</span>(m1 <span class="op">!=</span><span class="st"> </span>m1)</span>
<span id="cb127-2"><a href="tensors.html#cb127-2"></a><span class="co">#&gt; tensor([[False, False, False, False, False],</span></span>
<span id="cb127-3"><a href="tensors.html#cb127-3"></a><span class="co">#&gt;         [False, False, False, False, False],</span></span>
<span id="cb127-4"><a href="tensors.html#cb127-4"></a><span class="co">#&gt;         [False, False, False, False, False]])</span></span></code></pre></div>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="tensors.html#cb128-1"></a><span class="kw">print</span>(m2 <span class="op">==</span><span class="st"> </span>m2)</span>
<span id="cb128-2"><a href="tensors.html#cb128-2"></a><span class="co">#&gt; tensor([[True, True, True, True, True],</span></span>
<span id="cb128-3"><a href="tensors.html#cb128-3"></a><span class="co">#&gt;         [True, True, True, True, True],</span></span>
<span id="cb128-4"><a href="tensors.html#cb128-4"></a><span class="co">#&gt;         [True, True, True, True, True]])</span></span></code></pre></div>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="tensors.html#cb129-1"></a><span class="co"># AND</span></span>
<span id="cb129-2"><a href="tensors.html#cb129-2"></a>m1 <span class="op">&amp;</span><span class="st"> </span>m1</span>
<span id="cb129-3"><a href="tensors.html#cb129-3"></a><span class="co">#&gt; tensor([[1, 1, 1, 1, 1],</span></span>
<span id="cb129-4"><a href="tensors.html#cb129-4"></a><span class="co">#&gt;         [1, 1, 1, 1, 1],</span></span>
<span id="cb129-5"><a href="tensors.html#cb129-5"></a><span class="co">#&gt;         [1, 1, 1, 1, 1]], dtype=torch.uint8)</span></span></code></pre></div>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="tensors.html#cb130-1"></a><span class="co"># OR</span></span>
<span id="cb130-2"><a href="tensors.html#cb130-2"></a>m0 <span class="op">|</span><span class="st"> </span>m2</span>
<span id="cb130-3"><a href="tensors.html#cb130-3"></a><span class="co">#&gt; tensor([[1, 0, 0, 0, 0],</span></span>
<span id="cb130-4"><a href="tensors.html#cb130-4"></a><span class="co">#&gt;         [0, 1, 0, 0, 0],</span></span>
<span id="cb130-5"><a href="tensors.html#cb130-5"></a><span class="co">#&gt;         [0, 0, 1, 0, 0]], dtype=torch.uint8)</span></span></code></pre></div>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="tensors.html#cb131-1"></a><span class="co"># OR</span></span>
<span id="cb131-2"><a href="tensors.html#cb131-2"></a>m1 <span class="op">|</span><span class="st"> </span>m2</span>
<span id="cb131-3"><a href="tensors.html#cb131-3"></a><span class="co">#&gt; tensor([[1, 1, 1, 1, 1],</span></span>
<span id="cb131-4"><a href="tensors.html#cb131-4"></a><span class="co">#&gt;         [1, 1, 1, 1, 1],</span></span>
<span id="cb131-5"><a href="tensors.html#cb131-5"></a><span class="co">#&gt;         [1, 1, 1, 1, 1]], dtype=torch.uint8)</span></span></code></pre></div>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="tensors.html#cb132-1"></a><span class="co"># all_boolean &lt;- function(x) {</span></span>
<span id="cb132-2"><a href="tensors.html#cb132-2"></a><span class="co">#   # convert tensor of 1s and 0s to a unique boolean</span></span>
<span id="cb132-3"><a href="tensors.html#cb132-3"></a><span class="co">#   as.logical(torch$all(x)$numpy())</span></span>
<span id="cb132-4"><a href="tensors.html#cb132-4"></a><span class="co"># }</span></span>
<span id="cb132-5"><a href="tensors.html#cb132-5"></a></span>
<span id="cb132-6"><a href="tensors.html#cb132-6"></a><span class="co"># tensor is less than</span></span>
<span id="cb132-7"><a href="tensors.html#cb132-7"></a>A &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(60000L, 1L, 28L, 28L)</span>
<span id="cb132-8"><a href="tensors.html#cb132-8"></a>C &lt;-<span class="st"> </span>A <span class="op">*</span><span class="st"> </span><span class="fl">0.5</span></span>
<span id="cb132-9"><a href="tensors.html#cb132-9"></a></span>
<span id="cb132-10"><a href="tensors.html#cb132-10"></a><span class="co"># is C &lt; A</span></span>
<span id="cb132-11"><a href="tensors.html#cb132-11"></a><span class="kw">all</span>(torch<span class="op">$</span><span class="kw">lt</span>(C, A))</span>
<span id="cb132-12"><a href="tensors.html#cb132-12"></a><span class="co">#&gt; tensor(1, dtype=torch.uint8)</span></span>
<span id="cb132-13"><a href="tensors.html#cb132-13"></a><span class="kw">all</span>(C <span class="op">&lt;</span><span class="st"> </span>A)</span>
<span id="cb132-14"><a href="tensors.html#cb132-14"></a><span class="co">#&gt; tensor(1, dtype=torch.uint8)</span></span>
<span id="cb132-15"><a href="tensors.html#cb132-15"></a><span class="co"># is A &lt; C</span></span>
<span id="cb132-16"><a href="tensors.html#cb132-16"></a><span class="kw">all</span>(A <span class="op">&lt;</span><span class="st"> </span>C)</span>
<span id="cb132-17"><a href="tensors.html#cb132-17"></a><span class="co">#&gt; tensor(0, dtype=torch.uint8)</span></span></code></pre></div>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="tensors.html#cb133-1"></a><span class="co"># tensor is greater than</span></span>
<span id="cb133-2"><a href="tensors.html#cb133-2"></a>A &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(60000L, 1L, 28L, 28L)</span>
<span id="cb133-3"><a href="tensors.html#cb133-3"></a>D &lt;-<span class="st"> </span>A <span class="op">*</span><span class="st"> </span><span class="fl">2.0</span></span>
<span id="cb133-4"><a href="tensors.html#cb133-4"></a><span class="kw">all</span>(torch<span class="op">$</span><span class="kw">gt</span>(D, A))</span>
<span id="cb133-5"><a href="tensors.html#cb133-5"></a><span class="co">#&gt; tensor(1, dtype=torch.uint8)</span></span>
<span id="cb133-6"><a href="tensors.html#cb133-6"></a><span class="kw">all</span>(torch<span class="op">$</span><span class="kw">gt</span>(A, D))</span>
<span id="cb133-7"><a href="tensors.html#cb133-7"></a><span class="co">#&gt; tensor(0, dtype=torch.uint8)</span></span></code></pre></div>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="tensors.html#cb134-1"></a><span class="co"># tensor is less than or equal</span></span>
<span id="cb134-2"><a href="tensors.html#cb134-2"></a>A1 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">ones</span>(60000L, 1L, 28L, 28L)</span>
<span id="cb134-3"><a href="tensors.html#cb134-3"></a><span class="kw">all</span>(torch<span class="op">$</span><span class="kw">le</span>(A1, A1))</span>
<span id="cb134-4"><a href="tensors.html#cb134-4"></a><span class="co">#&gt; tensor(1, dtype=torch.uint8)</span></span>
<span id="cb134-5"><a href="tensors.html#cb134-5"></a><span class="kw">all</span>(A1 <span class="op">&lt;=</span><span class="st"> </span>A1)</span>
<span id="cb134-6"><a href="tensors.html#cb134-6"></a><span class="co">#&gt; tensor(1, dtype=torch.uint8)</span></span>
<span id="cb134-7"><a href="tensors.html#cb134-7"></a></span>
<span id="cb134-8"><a href="tensors.html#cb134-8"></a><span class="co"># tensor is greater than or equal</span></span>
<span id="cb134-9"><a href="tensors.html#cb134-9"></a>A0 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">zeros</span>(60000L, 1L, 28L, 28L)</span>
<span id="cb134-10"><a href="tensors.html#cb134-10"></a><span class="kw">all</span>(torch<span class="op">$</span><span class="kw">ge</span>(A0, A0))</span>
<span id="cb134-11"><a href="tensors.html#cb134-11"></a><span class="co">#&gt; tensor(1, dtype=torch.uint8)</span></span>
<span id="cb134-12"><a href="tensors.html#cb134-12"></a><span class="kw">all</span>(A0 <span class="op">&gt;=</span><span class="st"> </span>A0)</span>
<span id="cb134-13"><a href="tensors.html#cb134-13"></a><span class="co">#&gt; tensor(1, dtype=torch.uint8)</span></span>
<span id="cb134-14"><a href="tensors.html#cb134-14"></a></span>
<span id="cb134-15"><a href="tensors.html#cb134-15"></a><span class="kw">all</span>(A1 <span class="op">&gt;=</span><span class="st"> </span>A0)</span>
<span id="cb134-16"><a href="tensors.html#cb134-16"></a><span class="co">#&gt; tensor(1, dtype=torch.uint8)</span></span>
<span id="cb134-17"><a href="tensors.html#cb134-17"></a><span class="kw">all</span>(A1 <span class="op">&lt;=</span><span class="st"> </span>A0)</span>
<span id="cb134-18"><a href="tensors.html#cb134-18"></a><span class="co">#&gt; tensor(0, dtype=torch.uint8)</span></span></code></pre></div>
<div id="logical-not" class="section level3">
<h3><span class="header-section-number">3.11.1</span> Logical NOT</h3>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="tensors.html#cb135-1"></a>all_true &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">BoolTensor</span>(<span class="kw">list</span>(<span class="ot">TRUE</span>, <span class="ot">TRUE</span>, <span class="ot">TRUE</span>, <span class="ot">TRUE</span>))</span>
<span id="cb135-2"><a href="tensors.html#cb135-2"></a>all_true</span>
<span id="cb135-3"><a href="tensors.html#cb135-3"></a><span class="co">#&gt; tensor([True, True, True, True])</span></span>
<span id="cb135-4"><a href="tensors.html#cb135-4"></a></span>
<span id="cb135-5"><a href="tensors.html#cb135-5"></a><span class="co"># logical NOT</span></span>
<span id="cb135-6"><a href="tensors.html#cb135-6"></a>not_all_true &lt;-<span class="st"> </span><span class="op">!</span>all_true</span>
<span id="cb135-7"><a href="tensors.html#cb135-7"></a>not_all_true</span>
<span id="cb135-8"><a href="tensors.html#cb135-8"></a><span class="co">#&gt; tensor([False, False, False, False])</span></span></code></pre></div>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="tensors.html#cb136-1"></a>diag &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">eye</span>(5L)</span>
<span id="cb136-2"><a href="tensors.html#cb136-2"></a>diag</span>
<span id="cb136-3"><a href="tensors.html#cb136-3"></a><span class="co">#&gt; tensor([[1., 0., 0., 0., 0.],</span></span>
<span id="cb136-4"><a href="tensors.html#cb136-4"></a><span class="co">#&gt;         [0., 1., 0., 0., 0.],</span></span>
<span id="cb136-5"><a href="tensors.html#cb136-5"></a><span class="co">#&gt;         [0., 0., 1., 0., 0.],</span></span>
<span id="cb136-6"><a href="tensors.html#cb136-6"></a><span class="co">#&gt;         [0., 0., 0., 1., 0.],</span></span>
<span id="cb136-7"><a href="tensors.html#cb136-7"></a><span class="co">#&gt;         [0., 0., 0., 0., 1.]])</span></span>
<span id="cb136-8"><a href="tensors.html#cb136-8"></a></span>
<span id="cb136-9"><a href="tensors.html#cb136-9"></a><span class="co"># logical NOT</span></span>
<span id="cb136-10"><a href="tensors.html#cb136-10"></a>not_diag &lt;-<span class="st"> </span><span class="op">!</span>diag</span>
<span id="cb136-11"><a href="tensors.html#cb136-11"></a></span>
<span id="cb136-12"><a href="tensors.html#cb136-12"></a><span class="co"># convert to integer</span></span>
<span id="cb136-13"><a href="tensors.html#cb136-13"></a>not_diag<span class="op">$</span><span class="kw">to</span>(<span class="dt">dtype=</span>torch<span class="op">$</span>uint8)</span>
<span id="cb136-14"><a href="tensors.html#cb136-14"></a><span class="co">#&gt; tensor([[0, 1, 1, 1, 1],</span></span>
<span id="cb136-15"><a href="tensors.html#cb136-15"></a><span class="co">#&gt;         [1, 0, 1, 1, 1],</span></span>
<span id="cb136-16"><a href="tensors.html#cb136-16"></a><span class="co">#&gt;         [1, 1, 0, 1, 1],</span></span>
<span id="cb136-17"><a href="tensors.html#cb136-17"></a><span class="co">#&gt;         [1, 1, 1, 0, 1],</span></span>
<span id="cb136-18"><a href="tensors.html#cb136-18"></a><span class="co">#&gt;         [1, 1, 1, 1, 0]], dtype=torch.uint8)</span></span></code></pre></div>
</div>
</div>
<div id="distributions" class="section level2">
<h2><span class="header-section-number">3.12</span> Distributions</h2>
<p>Initialize a tensor randomized with a normal distribution with mean=0, var=1:</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="tensors.html#cb137-1"></a>a  &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">randn</span>(5L, 7L)</span>
<span id="cb137-2"><a href="tensors.html#cb137-2"></a><span class="kw">print</span>(a)</span>
<span id="cb137-3"><a href="tensors.html#cb137-3"></a><span class="co">#&gt; tensor([[ 2.0480, -0.1352,  0.6204,  0.1367, -0.2817,  0.6847,  0.1306],</span></span>
<span id="cb137-4"><a href="tensors.html#cb137-4"></a><span class="co">#&gt;         [-0.7534, -0.2599, -0.0793,  1.4319, -0.5261, -0.1281,  0.1019],</span></span>
<span id="cb137-5"><a href="tensors.html#cb137-5"></a><span class="co">#&gt;         [ 1.0257, -0.3640, -0.4557, -0.2172, -1.5850,  0.4059,  0.7548],</span></span>
<span id="cb137-6"><a href="tensors.html#cb137-6"></a><span class="co">#&gt;         [ 1.0810, -0.7908, -0.6013, -0.9036, -0.0451,  2.0575,  0.0941],</span></span>
<span id="cb137-7"><a href="tensors.html#cb137-7"></a><span class="co">#&gt;         [-0.8867,  1.0867,  2.2219, -0.9868,  0.6169, -0.6605,  0.8475]])</span></span>
<span id="cb137-8"><a href="tensors.html#cb137-8"></a><span class="kw">print</span>(a<span class="op">$</span><span class="kw">size</span>())</span>
<span id="cb137-9"><a href="tensors.html#cb137-9"></a><span class="co">#&gt; torch.Size([5, 7])</span></span></code></pre></div>
<div id="uniform-matrix" class="section level3">
<h3><span class="header-section-number">3.12.1</span> Uniform matrix</h3>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="tensors.html#cb138-1"></a><span class="kw">library</span>(rTorch)</span>
<span id="cb138-2"><a href="tensors.html#cb138-2"></a></span>
<span id="cb138-3"><a href="tensors.html#cb138-3"></a><span class="co"># 3x5 matrix uniformly distributed between 0 and 1</span></span>
<span id="cb138-4"><a href="tensors.html#cb138-4"></a>mat0 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(3L, 5L)<span class="op">$</span><span class="kw">uniform_</span>(0L, 1L)</span>
<span id="cb138-5"><a href="tensors.html#cb138-5"></a></span>
<span id="cb138-6"><a href="tensors.html#cb138-6"></a><span class="co"># fill a 3x5 matrix with 0.1</span></span>
<span id="cb138-7"><a href="tensors.html#cb138-7"></a>mat1 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(3L, 5L)<span class="op">$</span><span class="kw">uniform_</span>(<span class="fl">0.1</span>, <span class="fl">0.1</span>)</span>
<span id="cb138-8"><a href="tensors.html#cb138-8"></a></span>
<span id="cb138-9"><a href="tensors.html#cb138-9"></a><span class="co"># a vector with all ones</span></span>
<span id="cb138-10"><a href="tensors.html#cb138-10"></a>mat2 &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">FloatTensor</span>(5L)<span class="op">$</span><span class="kw">uniform_</span>(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb138-11"><a href="tensors.html#cb138-11"></a></span>
<span id="cb138-12"><a href="tensors.html#cb138-12"></a>mat0</span>
<span id="cb138-13"><a href="tensors.html#cb138-13"></a><span class="co">#&gt; tensor([[0.8585, 0.0753, 0.7991, 0.2967, 0.3494],</span></span>
<span id="cb138-14"><a href="tensors.html#cb138-14"></a><span class="co">#&gt;         [0.2219, 0.3422, 0.8052, 0.0350, 0.6052],</span></span>
<span id="cb138-15"><a href="tensors.html#cb138-15"></a><span class="co">#&gt;         [0.3641, 0.8269, 0.5972, 0.7578, 0.2448]], dtype=torch.float32)</span></span>
<span id="cb138-16"><a href="tensors.html#cb138-16"></a>mat1</span>
<span id="cb138-17"><a href="tensors.html#cb138-17"></a><span class="co">#&gt; tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000],</span></span>
<span id="cb138-18"><a href="tensors.html#cb138-18"></a><span class="co">#&gt;         [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],</span></span>
<span id="cb138-19"><a href="tensors.html#cb138-19"></a><span class="co">#&gt;         [0.1000, 0.1000, 0.1000, 0.1000, 0.1000]], dtype=torch.float32)</span></span></code></pre></div>
</div>
<div id="binomial-distribution" class="section level3">
<h3><span class="header-section-number">3.12.2</span> Binomial distribution</h3>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="tensors.html#cb139-1"></a>Binomial &lt;-<span class="st"> </span>torch<span class="op">$</span>distributions<span class="op">$</span>binomial<span class="op">$</span>Binomial</span>
<span id="cb139-2"><a href="tensors.html#cb139-2"></a></span>
<span id="cb139-3"><a href="tensors.html#cb139-3"></a>m =<span class="st"> </span><span class="kw">Binomial</span>(<span class="dv">100</span>, torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(<span class="dv">0</span> , <span class="fl">.2</span>, <span class="fl">.8</span>, <span class="dv">1</span>)))</span>
<span id="cb139-4"><a href="tensors.html#cb139-4"></a>(<span class="dt">x =</span> m<span class="op">$</span><span class="kw">sample</span>())</span>
<span id="cb139-5"><a href="tensors.html#cb139-5"></a><span class="co">#&gt; tensor([  0.,  19.,  76., 100.])</span></span></code></pre></div>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="tensors.html#cb140-1"></a>m =<span class="st"> </span><span class="kw">Binomial</span>(torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(<span class="kw">list</span>(<span class="fl">5.</span>), <span class="kw">list</span>(<span class="fl">10.</span>))), </span>
<span id="cb140-2"><a href="tensors.html#cb140-2"></a>             torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(<span class="fl">0.5</span>, <span class="fl">0.8</span>)))</span>
<span id="cb140-3"><a href="tensors.html#cb140-3"></a>(<span class="dt">x =</span> m<span class="op">$</span><span class="kw">sample</span>())</span>
<span id="cb140-4"><a href="tensors.html#cb140-4"></a><span class="co">#&gt; tensor([[3., 4.],</span></span>
<span id="cb140-5"><a href="tensors.html#cb140-5"></a><span class="co">#&gt;         [4., 9.]])</span></span></code></pre></div>
</div>
<div id="exponential-distribution" class="section level3">
<h3><span class="header-section-number">3.12.3</span> Exponential distribution</h3>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="tensors.html#cb141-1"></a>Exponential &lt;-<span class="st"> </span>torch<span class="op">$</span>distributions<span class="op">$</span>exponential<span class="op">$</span>Exponential</span>
<span id="cb141-2"><a href="tensors.html#cb141-2"></a></span>
<span id="cb141-3"><a href="tensors.html#cb141-3"></a>m =<span class="st"> </span><span class="kw">Exponential</span>(torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(<span class="fl">1.0</span>)))</span>
<span id="cb141-4"><a href="tensors.html#cb141-4"></a>m<span class="op">$</span><span class="kw">sample</span>()  <span class="co"># Exponential distributed with rate=1</span></span>
<span id="cb141-5"><a href="tensors.html#cb141-5"></a><span class="co">#&gt; tensor([0.1893])</span></span></code></pre></div>
</div>
<div id="weibull-distribution" class="section level3">
<h3><span class="header-section-number">3.12.4</span> Weibull distribution</h3>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="tensors.html#cb142-1"></a>Weibull &lt;-<span class="st"> </span>torch<span class="op">$</span>distributions<span class="op">$</span>weibull<span class="op">$</span>Weibull</span>
<span id="cb142-2"><a href="tensors.html#cb142-2"></a></span>
<span id="cb142-3"><a href="tensors.html#cb142-3"></a>m =<span class="st"> </span><span class="kw">Weibull</span>(torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(<span class="fl">1.0</span>)), torch<span class="op">$</span><span class="kw">tensor</span>(<span class="kw">list</span>(<span class="fl">1.0</span>)))</span>
<span id="cb142-4"><a href="tensors.html#cb142-4"></a>m<span class="op">$</span><span class="kw">sample</span>()  <span class="co"># sample from a Weibull distribution with scale=1, concentration=1</span></span>
<span id="cb142-5"><a href="tensors.html#cb142-5"></a><span class="co">#&gt; tensor([1.5254])</span></span></code></pre></div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="rtorch-vs-pytorch-whats-different.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="linearalgebra.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
